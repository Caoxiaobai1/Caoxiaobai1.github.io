
  <!DOCTYPE html>
  <html lang="en"  
    
      data-theme-mode="auto"
    
  >
  <head>
  
  <meta charset="utf-8">
  

  

  

  <script>window.REIMU_CONFIG = {};window.REIMU_CONFIG.icon_font = '4552607_4k4bc36ef96';window.REIMU_CONFIG.clipboard_tips = {"success":{"en":"Copy successfully (*^▽^*)","zh-CN":"复制成功 (*^▽^*)","zh-TW":"複製成功 (*^▽^*)","ja":"コピー成功 (*^▽^*)","pt-BR":"Copiado com sucesso (*^▽^*)"},"fail":{"en":"Copy failed (ﾟ⊿ﾟ)ﾂ","zh-CN":"复制失败 (ﾟ⊿ﾟ)ﾂ","zh-TW":"複製失敗 (ﾟ⊿ﾟ)ﾂ","ja":"コピー失敗 (ﾟ⊿ﾟ)ﾂ","pt-BR":"Falha ao copiar (ﾟ⊿ﾟ)ﾂ"},"copyright":{"enable":false,"count":50,"license_type":"by-nc-sa"}};window.REIMU_CONFIG.clipboard_tips.copyright.content = 'All articles on this blog are licensed under the BY-NC-SA license agreement unless otherwise stated. Please indicate the source when reprinting!';window.REIMU_CONFIG.code_block = {"expand":true};window.REIMU_CONFIG.base = 'https://caoxiaobai1.github.io';window.REIMU_CONFIG.i18n_languages = ["en"];</script>
  
  <title>
    Flink基础入门 |
    
    DON&#39;T SAY &#34;LAZY&#34;
  </title>
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  
    <link rel="preload" as="style" href="https://fontsapi.zeoseven.com/292/main/result.css" onload="this.rel&#x3D;&#39;stylesheet&#39;" crossorigin>
  
  
    <link rel="preconnect" href="https://fonts.gstatic.com/" crossorigin><link rel="preload" as="style" href="https://fonts.googleapis.com/css?family=Mulish:400,400italic,700,700italic%7CNoto%20Serif%20SC:400,400italic,700,700italic&display=swap"><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Mulish:400,400italic,700,700italic%7CNoto%20Serif%20SC:400,400italic,700,700italic&display=swap" media="print" onload="this.media&#x3D;&#39;all&#39;">
  
  
    <link rel="preload" href="//at.alicdn.com/t/c/font_4552607_4k4bc36ef96.woff2" as="font" type="font/woff2" crossorigin="anonymous">
  
  
    
<link rel="stylesheet" href="/css/loader.css">

  
  
    <meta name="description" content="​			Apache Flink是一个框架和分布式处理引擎，用于对无界和有界数据流进行有状态计算。Flink设计为在所有常见的集群环境中运行，以内存速度和任何规模执行计算。    ​		本次课程基于2021年05月28日发布的Flink 1.13.1版本讲解，此版本重要功能：让流处理应用的使用和普通应用一样简单和自然。https:&#x2F;&#x2F;developer.aliyun.com&#x2F;article&#x2F;78">
<meta property="og:type" content="article">
<meta property="og:title" content="Flink基础入门">
<meta property="og:url" content="https://caoxiaobai1.github.io/en/2022/11/28/Flink%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8/index.html">
<meta property="og:site_name" content="DON&#39;T SAY &quot;LAZY&quot;">
<meta property="og:description" content="​			Apache Flink是一个框架和分布式处理引擎，用于对无界和有界数据流进行有状态计算。Flink设计为在所有常见的集群环境中运行，以内存速度和任何规模执行计算。    ​		本次课程基于2021年05月28日发布的Flink 1.13.1版本讲解，此版本重要功能：让流处理应用的使用和普通应用一样简单和自然。https:&#x2F;&#x2F;developer.aliyun.com&#x2F;article&#x2F;78">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://caoxiaobai1.github.io/en/2022/11/28/Flink%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8/1602831101602.png">
<meta property="og:image" content="https://caoxiaobai1.github.io/en/2022/11/28/Flink%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8/1633395619727.png">
<meta property="og:image" content="https://caoxiaobai1.github.io/en/2022/11/28/Flink%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8/1633392172368.png">
<meta property="og:image" content="https://caoxiaobai1.github.io/en/2022/11/28/Flink%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8/1633392749387.png">
<meta property="og:image" content="https://caoxiaobai1.github.io/en/2022/11/28/Flink%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8/1633392846884.png">
<meta property="og:image" content="https://caoxiaobai1.github.io/en/2022/11/28/Flink%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8/1614734097803.png">
<meta property="og:image" content="https://caoxiaobai1.github.io/en/2022/11/28/Flink%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8/bounded-unbounded.png">
<meta property="og:image" content="https://caoxiaobai1.github.io/en/2022/11/28/Flink%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8/1644719616023.png">
<meta property="og:image" content="https://caoxiaobai1.github.io/en/2022/11/28/Flink%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8/1629899621701.png">
<meta property="og:image" content="https://caoxiaobai1.github.io/en/2022/11/28/Flink%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8/1614735779720.png">
<meta property="og:image" content="https://caoxiaobai1.github.io/en/2022/11/28/Flink%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8/1614736092102.png">
<meta property="og:image" content="https://caoxiaobai1.github.io/en/2022/11/28/Flink%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8/1633525384745.png">
<meta property="og:image" content="https://caoxiaobai1.github.io/en/2022/11/28/Flink%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8/1614734865437.png">
<meta property="og:image" content="https://caoxiaobai1.github.io/en/2022/11/28/Flink%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8/1614734748662.png">
<meta property="og:image" content="https://caoxiaobai1.github.io/en/2022/11/28/Flink%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8/1633525474698.png">
<meta property="og:image" content="https://caoxiaobai1.github.io/en/2022/11/28/Flink%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8/1633525569335.png">
<meta property="og:image" content="https://caoxiaobai1.github.io/en/2022/11/28/Flink%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8/1629901961306.png">
<meta property="og:image" content="https://caoxiaobai1.github.io/en/2022/11/28/Flink%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8/1629901989018.png">
<meta property="og:image" content="https://caoxiaobai1.github.io/en/2022/11/28/Flink%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8/1633397327645.png">
<meta property="og:image" content="https://caoxiaobai1.github.io/en/2022/11/28/Flink%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8/1614737695168.png">
<meta property="og:image" content="https://caoxiaobai1.github.io/en/2022/11/28/Flink%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8/1633399009714.png">
<meta property="og:image" content="https://caoxiaobai1.github.io/en/2022/11/28/Flink%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8/1629903243124.png">
<meta property="og:image" content="https://caoxiaobai1.github.io/en/2022/11/28/Flink%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8/1629903504528.png">
<meta property="og:image" content="https://caoxiaobai1.github.io/en/2022/11/28/Flink%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8/1629903674802.png">
<meta property="og:image" content="https://caoxiaobai1.github.io/en/2022/11/28/Flink%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8/1629903804060.png">
<meta property="og:image" content="https://caoxiaobai1.github.io/en/2022/11/28/Flink%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8/1633489044621.png">
<meta property="og:image" content="https://caoxiaobai1.github.io/en/2022/11/28/Flink%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8/1629903836486.png">
<meta property="og:image" content="https://caoxiaobai1.github.io/en/2022/11/28/Flink%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8/1633412578726.png">
<meta property="og:image" content="https://caoxiaobai1.github.io/en/2022/11/28/Flink%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8/1633525750169.png">
<meta property="og:image" content="https://caoxiaobai1.github.io/en/2022/11/28/Flink%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8/1633412935980.png">
<meta property="og:image" content="https://caoxiaobai1.github.io/en/2022/11/28/Flink%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8/1648421643678.png">
<meta property="og:image" content="https://caoxiaobai1.github.io/en/2022/11/28/Flink%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8/1633414183605.png">
<meta property="og:image" content="https://caoxiaobai1.github.io/en/2022/11/28/Flink%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8/1614741619007.png">
<meta property="og:image" content="https://caoxiaobai1.github.io/en/2022/11/28/Flink%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8/1614741637978.png">
<meta property="og:image" content="https://caoxiaobai1.github.io/en/2022/11/28/Flink%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8/1633419163511.png">
<meta property="og:image" content="https://caoxiaobai1.github.io/en/2022/11/28/Flink%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8/1628910791520.png">
<meta property="og:image" content="https://caoxiaobai1.github.io/en/2022/11/28/Flink%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8/1633419832998.png">
<meta property="og:image" content="https://caoxiaobai1.github.io/en/2022/11/28/Flink%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8/1633420098242.png">
<meta property="og:image" content="https://caoxiaobai1.github.io/en/2022/11/28/Flink%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8/1633420117287.png">
<meta property="og:image" content="https://caoxiaobai1.github.io/en/2022/11/28/Flink%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8/1633420180093.png">
<meta property="og:image" content="https://caoxiaobai1.github.io/en/2022/11/28/Flink%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8/1633420246834.png">
<meta property="og:image" content="https://caoxiaobai1.github.io/en/2022/11/28/Flink%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8/1633420700445.png">
<meta property="og:image" content="https://caoxiaobai1.github.io/en/2022/11/28/Flink%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8/1633420505322.png">
<meta property="og:image" content="https://caoxiaobai1.github.io/en/2022/11/28/Flink%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8/1633420612315.png">
<meta property="og:image" content="https://caoxiaobai1.github.io/en/2022/11/28/Flink%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8/1644670949884.png">
<meta property="og:image" content="https://caoxiaobai1.github.io/en/2022/11/28/Flink%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8/1614743548233.png">
<meta property="og:image" content="https://caoxiaobai1.github.io/en/2022/11/28/Flink%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8/1633421482610.png">
<meta property="og:image" content="https://caoxiaobai1.github.io/en/2022/11/28/Flink%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8/1633421994734.png">
<meta property="og:image" content="https://caoxiaobai1.github.io/en/2022/11/28/Flink%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8/1633422040826.png">
<meta property="og:image" content="https://caoxiaobai1.github.io/en/2022/11/28/Flink%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8/1633422420531.png">
<meta property="og:image" content="https://caoxiaobai1.github.io/en/2022/11/28/Flink%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8/1633422301964.png">
<meta property="og:image" content="https://caoxiaobai1.github.io/en/2022/11/28/Flink%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8/1633422457779.png">
<meta property="og:image" content="https://caoxiaobai1.github.io/en/2022/11/28/Flink%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8/1633422618479.png">
<meta property="og:image" content="https://caoxiaobai1.github.io/en/2022/11/28/Flink%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8/1644670949884.png">
<meta property="og:image" content="https://caoxiaobai1.github.io/en/2022/11/28/Flink%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8/1644670962923.png">
<meta property="og:image" content="https://caoxiaobai1.github.io/en/2022/11/28/Flink%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8/1614744989801.png">
<meta property="og:image" content="https://caoxiaobai1.github.io/en/2022/11/28/Flink%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8/1633424157381.png">
<meta property="og:image" content="https://caoxiaobai1.github.io/en/2022/11/28/Flink%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8/1633424730324.png">
<meta property="og:image" content="https://caoxiaobai1.github.io/en/2022/11/28/Flink%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8/1633424799351.png">
<meta property="og:image" content="https://caoxiaobai1.github.io/en/2022/11/28/Flink%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8/1633424955842.png">
<meta property="og:image" content="https://caoxiaobai1.github.io/en/2022/11/28/Flink%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8/1633425037238.png">
<meta property="og:image" content="https://caoxiaobai1.github.io/en/2022/11/28/Flink%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8/1652166719519.png">
<meta property="og:image" content="https://caoxiaobai1.github.io/en/2022/11/28/Flink%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8/1633428933682.png">
<meta property="og:image" content="https://caoxiaobai1.github.io/en/2022/11/28/Flink%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8/1629929588137.png">
<meta property="og:image" content="https://caoxiaobai1.github.io/en/2022/11/28/Flink%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8/1614763576727.png">
<meta property="og:image" content="https://caoxiaobai1.github.io/en/2022/11/28/Flink%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8/1633433408535.png">
<meta property="og:image" content="https://caoxiaobai1.github.io/en/2022/11/28/Flink%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8/1633437485506.png">
<meta property="og:image" content="https://caoxiaobai1.github.io/en/2022/11/28/Flink%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8/1633421482610.png">
<meta property="og:image" content="https://caoxiaobai1.github.io/en/2022/11/28/Flink%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8/1652169020141.png">
<meta property="og:image" content="https://caoxiaobai1.github.io/en/2022/11/28/Flink%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8/1633435043735.png">
<meta property="og:image" content="https://caoxiaobai1.github.io/en/2022/11/28/Flink%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8/616953-20190705091842823-1472310397.png">
<meta property="og:image" content="https://caoxiaobai1.github.io/en/2022/11/28/Flink%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8/1633422301964.png">
<meta property="og:image" content="https://caoxiaobai1.github.io/en/2022/11/28/Flink%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8/1633442327570.png">
<meta property="og:image" content="https://caoxiaobai1.github.io/en/2022/11/28/Flink%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8/1633442372444.png">
<meta property="og:image" content="https://caoxiaobai1.github.io/en/2022/11/28/Flink%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8/1633443314472.png">
<meta property="og:image" content="https://caoxiaobai1.github.io/en/2022/11/28/Flink%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8/1633443391587.png">
<meta property="og:image" content="https://caoxiaobai1.github.io/en/2022/11/28/Flink%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8/616953-20190705091903367-1915964437.png">
<meta property="og:image" content="https://caoxiaobai1.github.io/en/2022/11/28/Flink%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8/1633444275790.png">
<meta property="og:image" content="https://caoxiaobai1.github.io/en/2022/11/28/Flink%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8/1633444352887.png">
<meta property="og:image" content="https://caoxiaobai1.github.io/en/2022/11/28/Flink%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8/1633444546416.png">
<meta property="og:image" content="https://caoxiaobai1.github.io/en/2022/11/28/Flink%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8/1633436605167.png">
<meta property="og:image" content="https://caoxiaobai1.github.io/en/2022/11/28/Flink%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8/1633436948989.png">
<meta property="og:image" content="https://caoxiaobai1.github.io/en/2022/11/28/Flink%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8/1633445478494.png">
<meta property="og:image" content="https://caoxiaobai1.github.io/en/2022/11/28/Flink%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8/1633445508701.png">
<meta property="og:image" content="https://caoxiaobai1.github.io/en/2022/11/28/Flink%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8/1648681334840.png">
<meta property="og:image" content="https://caoxiaobai1.github.io/en/2022/11/28/Flink%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8/1614758479527.png">
<meta property="og:image" content="https://caoxiaobai1.github.io/en/2022/11/28/Flink%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8/1614758699392.png">
<meta property="og:image" content="https://caoxiaobai1.github.io/en/2022/11/28/Flink%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8/1614758736610.png">
<meta property="og:image" content="https://caoxiaobai1.github.io/en/2022/11/28/Flink%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8/1633445886187.png">
<meta property="og:image" content="https://caoxiaobai1.github.io/en/2022/11/28/Flink%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8/1633446037078.png">
<meta property="og:image" content="https://caoxiaobai1.github.io/en/2022/11/28/Flink%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8/1629963813924.png">
<meta property="og:image" content="https://caoxiaobai1.github.io/en/2022/11/28/Flink%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8/1633446519262.png">
<meta property="og:image" content="https://caoxiaobai1.github.io/en/2022/11/28/Flink%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8/1633446557864.png">
<meta property="og:image" content="https://caoxiaobai1.github.io/en/2022/11/28/Flink%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8/1614734865437.png">
<meta property="og:image" content="https://caoxiaobai1.github.io/en/2022/11/28/Flink%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8/1633447728418.png">
<meta property="og:image" content="https://caoxiaobai1.github.io/en/2022/11/28/Flink%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8/1630745360506.png">
<meta property="og:image" content="https://caoxiaobai1.github.io/en/2022/11/28/Flink%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8/1652322463648.png">
<meta property="og:image" content="https://caoxiaobai1.github.io/en/2022/11/28/Flink%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8/1633448743408.png">
<meta property="og:image" content="https://caoxiaobai1.github.io/en/2022/11/28/Flink%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8/1633448931513.png">
<meta property="og:image" content="https://caoxiaobai1.github.io/en/2022/11/28/Flink%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8/1633449004149.png">
<meta property="og:image" content="https://caoxiaobai1.github.io/en/2022/11/28/Flink%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8/1633449021605.png">
<meta property="og:image" content="https://caoxiaobai1.github.io/en/2022/11/28/Flink%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8/1633449120710.png">
<meta property="og:image" content="https://caoxiaobai1.github.io/en/2022/11/28/Flink%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8/1633396038901.png">
<meta property="og:image" content="https://caoxiaobai1.github.io/en/2022/11/28/Flink%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8/1629902040441.png">
<meta property="og:image" content="https://caoxiaobai1.github.io/en/2022/11/28/Flink%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8/1629902078825.png">
<meta property="og:image" content="https://caoxiaobai1.github.io/en/2022/11/28/Flink%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8/1629902139034.png">
<meta property="og:image" content="https://caoxiaobai1.github.io/en/2022/11/28/Flink%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8/1630749492194.png">
<meta property="og:image" content="https://caoxiaobai1.github.io/en/2022/11/28/Flink%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8/4092059-b6ff29d09ba6da97.png">
<meta property="og:image" content="https://caoxiaobai1.github.io/en/2022/11/28/Flink%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8/1614738294044.png">
<meta property="og:image" content="https://caoxiaobai1.github.io/en/2022/11/28/Flink%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8/1614738308219.png">
<meta property="og:image" content="https://caoxiaobai1.github.io/en/2022/11/28/Flink%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8/1614738339577.png">
<meta property="og:image" content="https://caoxiaobai1.github.io/en/2022/11/28/Flink%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8/1614738387322.png">
<meta property="og:image" content="https://caoxiaobai1.github.io/en/2022/11/28/Flink%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8/1633399667903.png">
<meta property="og:image" content="https://caoxiaobai1.github.io/en/2022/11/28/Flink%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8/1614738443208.png">
<meta property="og:image" content="https://caoxiaobai1.github.io/en/2022/11/28/Flink%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8/1630737225965.png">
<meta property="og:image" content="https://caoxiaobai1.github.io/en/2022/11/28/Flink%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8/1630737282282.png">
<meta property="og:image" content="https://caoxiaobai1.github.io/en/2022/11/28/Flink%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8/1630737374891.png">
<meta property="og:image" content="https://caoxiaobai1.github.io/en/2022/11/28/Flink%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8/1630737480781.png">
<meta property="og:image" content="https://caoxiaobai1.github.io/en/2022/11/28/Flink%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8/1633429200420.png">
<meta property="og:image" content="https://caoxiaobai1.github.io/en/2022/11/28/Flink%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8/42f2a89111db24fb3a28792ca3890b4a.png">
<meta property="og:image" content="https://caoxiaobai1.github.io/en/2022/11/28/Flink%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8/deployment_modes.svg">
<meta property="og:image" content="https://caoxiaobai1.github.io/en/2022/11/28/Flink%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8/1633436033528.png">
<meta property="og:image" content="https://caoxiaobai1.github.io/en/2022/11/28/Flink%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8/1633436301371.png">
<meta property="og:image" content="https://caoxiaobai1.github.io/en/2022/11/28/Flink%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8/1633436605167.png">
<meta property="og:image" content="https://caoxiaobai1.github.io/en/2022/11/28/Flink%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8/1633436948989.png">
<meta property="article:published_time" content="2022-11-28T12:30:20.000Z">
<meta property="article:modified_time" content="2025-09-08T05:59:12.990Z">
<meta property="article:author" content="小白">
<meta property="article:tag" content="flink">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://caoxiaobai1.github.io/en/2022/11/28/Flink%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8/1602831101602.png">
  
  
    <link rel="alternate" href="/atom.xml" title="DON'T SAY "LAZY"" type="application/atom+xml">
  
  
    <link rel="shortcut icon" href="/images/favicon.ico">
  
  
<link rel="stylesheet" href="/css/style.css">

  <link rel="preload" as="style" onload="this.onload&#x3D;null;this.rel&#x3D;&#39;stylesheet&#39;" href="https://npm.webcache.cn/photoswipe@5.4.4/dist/photoswipe.css" integrity="sha384-IfxC36XL&#x2F;toUyJ939C73PcgMuRzAZuIzZxE38drsmO5p6jD7ei+Zx&#x2F;1oA&#x2F;0l8ysE" crossorigin="anonymous">
  
    
      
        
<link rel="stylesheet" href="https://npm.webcache.cn/katex@0.16.22/dist/katex.min.css" integrity="sha384-5TcZemv2l&#x2F;9On385z&#x2F;&#x2F;&#x2F;+d7MSYlvIEw9FuZTIdZ14vJLqWphw7e7ZPuOiCHJcFCP" crossorigin="anonymous">

      
    
  
  
  
  
    
<script src="https://npm.webcache.cn/pace-js@1.2.4/pace.min.js" integrity="sha384-k6YtvFUEIuEFBdrLKJ3YAUbBki333tj1CSUisai5Cswsg9wcLNaPzsTHDswp4Az8" crossorigin="anonymous"></script>

  
  
    
<link rel="stylesheet" href="https://npm.webcache.cn/@reimujs/aos@0.1.2/dist/aos.css" integrity="sha384-GMRP93c6Hkz9JVKGAuRR3nTS7M07RwPgTFenXiosjq2VbVgvdDNcz1g6Mkj8AONa" crossorigin="anonymous">

  
  
    
<link rel="stylesheet" href="https://npm.webcache.cn/aplayer@1.10.1/dist/APlayer.min.css" integrity="sha384-tLMkTWh2pfXNWGFlUS0w1TFtRG5xZ9lPWFOooj+vDDLIL+xBGQU&#x2F;voDBY5XE2lVh" crossorigin="anonymous">

  
  
<meta name="generator" content="Hexo 7.3.0"></head>

  <body>
    
    
  <div id='loader'>
    <div class="loading-left-bg loading-bg"></div>
    <div class="loading-right-bg loading-bg"></div>
    <div class="spinner-box">
      <div class="loading-taichi rotate">
        
          <svg width="150" height="150" viewBox="0 0 1024 1024" class="icon" version="1.1" xmlns="https://www.w3.org/2000/svg" shape-rendering="geometricPrecision">
            <path d="M303.5 432A80 80 0 0 1 291.5 592A80 80 0 0 1 303.5 432z" fill="var(--red-1, #ff5252)" />
            <path d="M512 65A447 447 0 0 1 512 959L512 929A417 417 0 0 0 512 95A417 417 0 0 0 512 929L512 959A447 447 0 0 1 512 65z 
           M512 95A417 417 0 0 1 929 512A208.5 208.5 0 0 1 720.5 720.5L720.5 592A80 80 0 0 0 720.5 432A80 80 0 0 0 720.5 592L720.5 720.5A208.5 208.5 0 0 1 512 512A208.5 208.5 0 0 0 303.5 303.5A208.5 208.5 0 0 0 95 512A417 417 0 0 1 512 95z" fill="var(--red-1, #ff5252)" />
          </svg>
        
      </div>
      
      
        
      
      <div class="loading-word">Loading...</div>
    </div>
  </div>
  </div>
  <script>
    var time = null;
    var startLoading = () => {
      time = Date.now();
      document.getElementById('loader').classList.remove("loading");
    }
    var endLoading = () => {
      if (!time) {
        document.body.style.overflow = 'auto';
        document.getElementById('loader').classList.add("loading");
      } else {
        if (Date.now() - time > 500) {
          time = null;
          document.body.style.overflow = 'auto';
          document.getElementById('loader').classList.add("loading");
        } else {
          setTimeout(endLoading, 500 - (Date.now() - time));
          time = null;
        }
      }
    }
    window.addEventListener('DOMContentLoaded', endLoading);
    document.getElementById('loader').addEventListener('click', endLoading);
  </script>

<div id="copy-tooltip" style="pointer-events: none; opacity: 0; transition: all 0.2s ease; position: fixed;top: 50%;left: 50%;z-index: 999;transform: translate(-50%, -50%);color: white;background: rgba(0, 0, 0, 0.5);padding: 10px 15px;border-radius: 10px;">
</div>
<div id="heatmap-tooltip"></div>


    <div id="container">
      <div id="wrap">
        <div id="header-nav">
  <nav id="main-nav">
    
      
        <span class="main-nav-link-wrap">
          <div class="main-nav-icon icon rotate">
             
              &#xe62b;
             
          </div>
          <a class="main-nav-link" href="/en/">Home</a>
        </span>
      
        <span class="main-nav-link-wrap">
          <div class="main-nav-icon icon rotate">
             
              &#xe62b;
             
          </div>
          <a class="main-nav-link" href="/en/archives">Archives</a>
        </span>
      
        <span class="main-nav-link-wrap">
          <div class="main-nav-icon icon rotate">
             
              &#xe62b;
             
          </div>
          <a class="main-nav-link" href="/en/about">About</a>
        </span>
      
        <span class="main-nav-link-wrap">
          <div class="main-nav-icon icon rotate">
             
              &#xe62b;
             
          </div>
          <a class="main-nav-link" href="/en/friend">Friend</a>
        </span>
      
    
    <a id="main-nav-toggle" class="nav-icon"></a>
  </nav>
  <nav id="sub-nav">
    
      <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed" target="_blank"></a>
    
    
    
      <a id="nav-search-btn" class="nav-icon popup-trigger" title="Search"></a>
    
  </nav>
  
    
    <nav id="i18n-nav">
      <div class="custom-dropdown">
        <div class="select-selected" id="select-selected">
          <span id="nav-language-btn" class="nav-icon" style="padding: 0 20px 0 0"></span>
          <span id="selected-lang">English</span>
        </div>
        <ul class="select-items" id="select-items">
          
            <li data-value="zh-CN" >简体中文</li>
          
            <li data-value="en" class="selected">English</li>
          
        </ul>
      </div>
      <script>
        var selectSelected = document.getElementById("select-selected");
        var selectedLang = document.getElementById("selected-lang");
        var selectItems = document.getElementById("select-items");
        var selectOptions = selectItems.querySelectorAll("li");

        selectSelected.addEventListener("click", () => {
          selectItems.classList.toggle("show");
        });

        selectOptions.forEach((item) => {
          item.addEventListener("click", () => {
            const langMap = {};
            
              langMap['zh-CN'] = '/2022/11/28/Flink基础入门/';
            
              langMap['en'] = '/en/2022/11/28/Flink基础入门/';
            
            selectedLang.textContent = item.textContent;
            selectItems.classList.remove("show");
            selectOptions.forEach((option) => {
              option.classList.remove("selected");
            });
            item.classList.add("selected");
            window.location = langMap[item.dataset.value];
          });
        });

        document.addEventListener("click", (event) => {
          if (!event.target.closest(".custom-dropdown")) {
            selectItems.classList.remove("show");
          }
        });
      </script>
    </nav>
  
</div>
<header id="header">
  
    
      
        <picture>
          
        </picture>
        
          <img  fetchpriority="high" src="/images/banner.webp" alt="Flink基础入门">
        
      
    
  
  <div id="header-outer">
    <div id="header-title">
      
        
        
          <a href="/" id="logo">
            <h1 data-aos="slide-up">Flink基础入门</h1>
          </a>
        
      
      
        
        <h2 id="subtitle-wrap" data-aos="slide-down">
          
        </h2>
      
    </div>
  </div>
</header>

        <div id="content" class="sidebar-left"  >
          <aside id="sidebar">
  
  <div class="sidebar-wrapper-container sticky">
  
    
      <div id="aplayer" theme="var(--color-link)" data-aos="fade-up"></div>
    
    
  
 
  <div class="sidebar-wrapper">
    <div class="sidebar-wrap" data-aos="fade-up">
      
        
          <div class="sidebar-toc-sidebar"><h3 class="toc-title">Contents</h3>
<div class="sidebar-toc-wrapper toc-div-class" >
  
    <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%89%8D%E8%A8%80%E9%83%A8%E5%88%86%E7%9F%A5%E8%AF%86%E5%9B%9E%E9%A1%BE%E5%8F%8A%E8%AF%BE%E7%A8%8B%E7%9B%AE%E6%A0%87"><span class="toc-number">1.</span> <span class="toc-text"> 前言部分：知识回顾及课程目标</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%89%8D%E8%A8%801-%E8%AF%BE%E7%A8%8B%E5%89%8D%E8%A8%80%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E5%BC%95%E6%93%8E"><span class="toc-number">1.1.</span> <span class="toc-text"> [前言1]-课程前言：大数据分析引擎</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%89%8D%E8%A8%802-apache-flink-%E8%AF%BE%E7%A8%8B%E5%AE%89%E6%8E%92"><span class="toc-number">1.2.</span> <span class="toc-text"> [前言2]-Apache Flink  课程安排</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%89%8D%E8%A8%803-%E7%AC%AC1%E7%AB%A0%E8%AF%BE%E7%A8%8B%E5%86%85%E5%AE%B9%E6%8F%90%E7%BA%B2"><span class="toc-number">1.3.</span> <span class="toc-text"> [前言3]-第1章：课程内容提纲</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%AC%AC%E4%B8%80%E9%83%A8%E5%88%86flink-%E6%A1%86%E6%9E%B6%E6%A6%82%E8%BF%B03%E4%B8%AA%E5%B0%8F%E8%8A%82"><span class="toc-number">2.</span> <span class="toc-text"> 第一部分：Flink 框架概述【3个小节】</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#01-%E7%90%86%E8%A7%A3-flink-%E6%A6%82%E8%BF%B0%E4%B9%8B%E5%AE%98%E6%96%B9%E5%AE%9A%E4%B9%89"><span class="toc-number">2.1.</span> <span class="toc-text"> 01-[理解]-Flink 概述之官方定义</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#02-%E6%8E%8C%E6%8F%A1-flink-%E6%A6%82%E8%BF%B0%E4%B9%8B%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97%E6%80%9D%E6%83%B3"><span class="toc-number">2.2.</span> <span class="toc-text"> 02-[掌握]-Flink 概述之流式计算思想</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#03-%E4%BA%86%E8%A7%A3-flink-%E6%A6%82%E8%BF%B0%E4%B9%8B%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF"><span class="toc-number">2.3.</span> <span class="toc-text"> 03-[了解]-Flink 概述之应用场景</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%AC%AC%E4%BA%8C%E9%83%A8%E5%88%86flink-%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B29%E4%B8%AA%E5%B0%8F%E8%8A%82"><span class="toc-number">3.</span> <span class="toc-text"> 第二部分：Flink 安装部署【9个小节】</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#04-%E6%8E%8C%E6%8F%A1-%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2%E4%B9%8Bflink-cluster-%E6%9E%B6%E6%9E%84"><span class="toc-number">3.1.</span> <span class="toc-text"> 04-[掌握]-安装部署之Flink Cluster 架构</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#05-%E7%90%86%E8%A7%A3-%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2%E4%B9%8B%E6%9C%AC%E5%9C%B0%E9%9B%86%E7%BE%A4"><span class="toc-number">3.2.</span> <span class="toc-text"> 05-[理解]-安装部署之本地集群</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#06-%E7%90%86%E8%A7%A3-%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2%E4%B9%8Bstandalone-%E9%9B%86%E7%BE%A4"><span class="toc-number">3.3.</span> <span class="toc-text"> 06-[理解]-安装部署之Standalone 集群</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#07-%E4%BA%86%E8%A7%A3-%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2%E4%B9%8Bstandalone-ha"><span class="toc-number">3.4.</span> <span class="toc-text"> 07-[了解]-安装部署之Standalone HA</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#08-%E6%8E%8C%E6%8F%A1-flink-on-yarn%E4%B9%8B%E8%BF%90%E8%A1%8C%E6%B5%81%E7%A8%8B"><span class="toc-number">3.5.</span> <span class="toc-text"> 08-[掌握]-Flink on YARN之运行流程</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#09-%E7%90%86%E8%A7%A3-flink-on-yarn%E4%B9%8B%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2"><span class="toc-number">3.6.</span> <span class="toc-text"> 09-[理解]-Flink on YARN之安装部署</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#10-%E6%8E%8C%E6%8F%A1-flink-on-yarn%E4%B9%8Bsession-%E6%A8%A1%E5%BC%8F%E8%BF%90%E8%A1%8C"><span class="toc-number">3.7.</span> <span class="toc-text"> 10-[掌握]-Flink on YARN之Session 模式运行</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#11-%E6%8E%8C%E6%8F%A1-flink-on-yarn%E4%B9%8Bper-job-%E6%A8%A1%E5%BC%8F%E8%BF%90%E8%A1%8C"><span class="toc-number">3.8.</span> <span class="toc-text"> 11-[掌握]-Flink on YARN之Per-Job 模式运行</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#12-%E6%8E%8C%E6%8F%A1-flink-on-yarn%E4%B9%8Bapplication-%E6%A8%A1%E5%BC%8F%E8%BF%90%E8%A1%8C"><span class="toc-number">3.9.</span> <span class="toc-text"> 12-[掌握]-Flink on YARN之Application 模式运行</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%AC%AC%E4%B8%89%E9%83%A8%E5%88%86flink-%E5%85%A5%E9%97%A8%E6%A1%88%E4%BE%8B4%E4%B8%AA%E5%B0%8F%E8%8A%82"><span class="toc-number">4.</span> <span class="toc-text"> 第三部分：Flink 入门案例【4个小节】</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#13-%E6%8E%8C%E6%8F%A1-flink-%E5%85%A5%E9%97%A8%E6%A1%88%E4%BE%8B%E4%B9%8B%E7%BC%96%E7%A8%8B%E6%A8%A1%E5%9E%8B"><span class="toc-number">4.1.</span> <span class="toc-text"> 13-[掌握]-Flink 入门案例之编程模型</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#14-%E6%8E%8C%E6%8F%A1-flink-%E5%85%A5%E9%97%A8%E6%A1%88%E4%BE%8B%E4%B9%8Bwordcount%E6%89%B9%E5%A4%84%E7%90%86"><span class="toc-number">4.2.</span> <span class="toc-text"> 14-[掌握]-Flink 入门案例之WordCount【批处理】</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#15-%E6%8E%8C%E6%8F%A1-flink-%E5%85%A5%E9%97%A8%E6%A1%88%E4%BE%8B%E4%B9%8Bwordcount%E6%B5%81%E8%AE%A1%E7%AE%97"><span class="toc-number">4.3.</span> <span class="toc-text"> 15-[掌握]-Flink 入门案例之WordCount【流计算】</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#16-%E6%8E%8C%E6%8F%A1-flink-%E5%85%A5%E9%97%A8%E6%A1%88%E4%BE%8B%E4%B9%8B%E6%89%93%E5%8C%85%E9%83%A8%E7%BD%B2%E8%BF%90%E8%A1%8C"><span class="toc-number">4.4.</span> <span class="toc-text"> 16-[掌握]-Flink 入门案例之打包部署运行</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%99%84%E5%BD%95%E9%83%A8%E5%88%86%E6%B3%A8%E6%84%8F%E4%BA%8B%E9%A1%B9%E5%8F%8A%E6%89%A9%E5%B1%95%E5%86%85%E5%AE%B9"><span class="toc-number">5.</span> <span class="toc-text"> 附录部分：注意事项及扩展内容</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%99%84%E5%BD%951-%E6%B5%81%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E%E7%9A%84%E6%BC%94%E8%BF%9B"><span class="toc-number">5.1.</span> <span class="toc-text"> [附录1]-流计算引擎的演进</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%99%84%E5%BD%952-flink-%E6%A1%86%E6%9E%B6%E6%8A%80%E6%9C%AF%E6%A0%88"><span class="toc-number">5.2.</span> <span class="toc-text"> [附录2]-Flink 框架技术栈</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%99%84%E5%BD%953-flink-%E6%89%A9%E5%B1%95%E6%80%A7%E9%98%85%E8%AF%BB"><span class="toc-number">5.3.</span> <span class="toc-text"> [附录3]-Flink 扩展性阅读</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%99%84%E5%BD%954-flink-standalone-%E9%9B%86%E7%BE%A4%E5%9B%9E%E9%A1%BE"><span class="toc-number">5.4.</span> <span class="toc-text"> [附录4]-Flink Standalone 集群回顾</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%99%84%E5%BD%955-hadoop-yarn-%E5%9B%9E%E9%A1%BE%E5%A4%8D%E4%B9%A0"><span class="toc-number">5.5.</span> <span class="toc-text"> [附录5]-Hadoop YARN 回顾复习</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%99%84%E5%BD%956-flink-on-yarn-%E4%B8%89%E7%A7%8D%E9%83%A8%E7%BD%B2%E6%A8%A1%E5%BC%8F"><span class="toc-number">5.6.</span> <span class="toc-text"> [附录6]-Flink on YARN 三种部署模式</span></a></li></ol></li></ol>
  
</div>
</div>
          <div class="sidebar-common-sidebar hidden"><div class="sidebar-author">
  <img data-src="/avatar/avatar.webp" data-sizes="auto" alt="小白" class="lazyload">
  <div class="sidebar-author-name">小白</div>
  <div class="sidebar-description"></div>
</div>
<div class="sidebar-state">
  <div class="sidebar-state-article">
    <div>Post</div>
    <div class="sidebar-state-number">21</div>
  </div>
  <div class="sidebar-state-category">
    <div>Category</div>
    <div class="sidebar-state-number">6</div>
  </div>
  <div class="sidebar-state-tag">
    <div>Tag</div>
    <div class="sidebar-state-number">13</div>
  </div>
</div>
<div class="sidebar-social">
  
    <div class="icon-steam sidebar-social-icon">
      <a href=https://steamcommunity.com/id/yourname itemprop="url" target="_blank" aria-label="steam" rel="noopener external nofollow noreferrer"></a>
    </div>
  
</div>
<div class="sidebar-menu">
  
    
      <div class="sidebar-menu-link-wrap">
        <a class="sidebar-menu-link-dummy" href="/en/" aria-label="Home"></a>
        <div class="sidebar-menu-icon icon rotate">
          
            &#xe62b;
          
        </div>
        <div class="sidebar-menu-link">Home</div>
      </div>
    
      <div class="sidebar-menu-link-wrap">
        <a class="sidebar-menu-link-dummy" href="/en/archives" aria-label="Archives"></a>
        <div class="sidebar-menu-icon icon rotate">
          
            &#xe62b;
          
        </div>
        <div class="sidebar-menu-link">Archives</div>
      </div>
    
      <div class="sidebar-menu-link-wrap">
        <a class="sidebar-menu-link-dummy" href="/en/about" aria-label="About"></a>
        <div class="sidebar-menu-icon icon rotate">
          
            &#xe62b;
          
        </div>
        <div class="sidebar-menu-link">About</div>
      </div>
    
      <div class="sidebar-menu-link-wrap">
        <a class="sidebar-menu-link-dummy" href="/en/friend" aria-label="Friend"></a>
        <div class="sidebar-menu-icon icon rotate">
          
            &#xe62b;
          
        </div>
        <div class="sidebar-menu-link">Friend</div>
      </div>
    
  
</div>
</div>
        
      
      
        
          <div class="sidebar-btn-wrapper" style="position:static">
            <div class="sidebar-toc-btn current"></div>
            <div class="sidebar-common-btn"></div>
          </div>
        
      
    </div>
  </div>
  
  <div class="sidebar-widget">
  
  </div>
  
  </div>
  
</aside>

          <section id="main"><article id="post-Flink基础入门" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-inner" data-aos="fade-up">
    <div class="article-meta">
      <div class="article-date">
  <span class="article-date-link icon-calendar" data-aos="zoom-in">
    <time datetime="2022-11-28T12:30:20.000Z" itemprop="datePublished">2022-11-28</time>
    <time style="display: none;" id="post-update-time">2025-09-08</time>
  </span>
  
    <span class="article-date-link icon-calendar-plus" data-aos="zoom-in">
      <time datetime="2025-09-08T05:59:12.990Z" itemprop="dateModified">2025-09-08</time>
    </span>
  
</div>

      
  <div class="article-category">
    <a class="article-category-link" href="/en/categories/%E7%BC%96%E7%A8%8B/" data-aos="zoom-in">编程</a>
  </div>


    </div>
    <div class="hr-line"></div>
    

    <div class="e-content article-entry" itemprop="articleBody">
      
      
        <blockquote>
<p>​			Apache Flink是一个框架和分布式处理引擎，用于对无界和有界数据流进行有状态计算。Flink设计为在所有常见的集群环境中运行，以内存速度和任何规模执行计算。</p>
</blockquote>
<p><img src="1602831101602.png" alt="1602831101602" /></p>
<blockquote>
<p>​		本次课程基于<strong>2021年05月28日</strong>发布的<strong>Flink 1.13.1版本</strong>讲解，此版本重要功能：<strong>让流处理应用的使用和普通应用一样简单和自然</strong>。<a target="_blank" rel="noopener" href="https://developer.aliyun.com/article/780123">https://developer.aliyun.com/article/780123</a></p>
</blockquote>
<p><img src="1633395619727.png" alt="1633395619727" /></p>
<h2 id="前言部分知识回顾及课程目标"><a class="markdownIt-Anchor" href="#前言部分知识回顾及课程目标"></a> 前言部分：知识回顾及课程目标</h2>
<h3 id="前言1-课程前言大数据分析引擎"><a class="markdownIt-Anchor" href="#前言1-课程前言大数据分析引擎"></a> [前言1]-课程前言：大数据分析引擎</h3>
<hr />
<blockquote>
<p>整个大数据课程，分为四大阶段</p>
</blockquote>
<figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#1）、HADOOP 离线阶段：</span></span><br><span class="line">	基础课程（LINUX + ZOOKEEPER + HADOOP + HIVE）和项目课程</span><br><span class="line">	</span><br><span class="line"><span class="comment">#2）、SPARK 内存分析阶段：</span></span><br><span class="line">	基础课程（PySpark）和项目课程</span><br><span class="line">	</span><br><span class="line"><span class="comment">#3）、大数据实时存储阶段：</span></span><br><span class="line">	Flume、Redis、Kafka、HBase</span><br><span class="line">	</span><br><span class="line"><span class="comment">#4）、FLINK 流式计算阶段：</span></span><br><span class="line">	基础课程（FLINK：流计算及SQL&amp;Table API）和项目课程</span><br></pre></td></tr></table></figure>
<p><img src="1633392172368.png" alt="1633392172368" /></p>
<blockquote>
<p>大数据分析领域，数据分析类型：<mark>离线批处理分析（Batch）<mark>和</mark>实时流计算分析（Streaming）</mark>。</p>
</blockquote>
<figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">离线分析：</span><br><span class="line">	批处理（Batch Processing）</span><br><span class="line">实时分析：</span><br><span class="line">	流计算（Stream Processing）</span><br><span class="line">	</span><br><span class="line"></span><br><span class="line">MapReduce和Spark                        Flink</span><br><span class="line">    批处理                                 流处理（流计算）</span><br><span class="line">        每次处理多条数据                        每次处理1条数据</span><br><span class="line">        很多条数据一起处理                      1条1条数据处理</span><br><span class="line"></span><br><span class="line">    批处理                                 流计算</span><br><span class="line">        实时性没有太多要求                      实时性要求很高</span><br><span class="line">        当处理数据时，才运行Task                没有开始处理数据之前，运行Task</span><br><span class="line">        </span><br></pre></td></tr></table></figure>
<h3 id="前言2-apache-flink-课程安排"><a class="markdownIt-Anchor" href="#前言2-apache-flink-课程安排"></a> [前言2]-Apache Flink  课程安排</h3>
<hr />
<blockquote>
<p>Flink 基础理论的讲解，涉及到各种<mark>重要概念、原理和 API</mark>的用法，并且会有大量的示例代码实现：</p>
</blockquote>
<p><img src="1633392749387.png" alt="1633392749387" /></p>
<blockquote>
<ul>
<li>
<p>第一章、Flink-安装部署与快速入门：</p>
<p><a href="">Flink框架概述、环境安装部署、入门程序：词频统计WordCount及原理初步认识</a></p>
</li>
<li>
<p>第二章、Flink-流批一体化API：</p>
<p><a href="">Flink 流计算和批处理，进行实时和离线数据分析，主要API使用：Source数据源、Transformation数据转换、Sink数据终端和高级特性：<code>累加器和广播变量及分布式缓存</code></a></p>
</li>
<li>
<p><strong>第三章、Flink-高级特性</strong>：</p>
<p><a href="">Flink 四大基石：<code>State、Checkpoint</code>、<code>Window、Time</code>及异步IO、高级特性等等</a></p>
</li>
<li>
<p>第四章、Flink-<strong>Table API与SQL</strong>：</p>
<p><a href="">类似SparkSQL模块，提供Table API（DSL 编程）和SQL进行批处理和流计算</a></p>
</li>
</ul>
</blockquote>
<p>​			通过理论和实际的紧密结合，可以使学员对 Flink 有充分的认识和理解，并且通过对流处理原理的学习和与批处理架构的对比，可以对大数据处理架构有更全面的了解，为日后成长为架构师打下基础。</p>
<blockquote>
<p>Aapche Flink 分布式计算引擎学习文档：</p>
</blockquote>
<ul>
<li>1、Flink 官网：<a target="_blank" rel="noopener" href="https://flink.apache.org/">https://flink.apache.org/</a></li>
<li>2、Flink 中文社区：<a target="_blank" rel="noopener" href="https://flink-learning.org.cn/">https://flink-learning.org.cn/</a></li>
<li>3、Flink 软件下载：<a target="_blank" rel="noopener" href="https://archive.apache.org/dist/flink/">https://archive.apache.org/dist/flink/</a></li>
<li>4、Flink 分享B站：<a target="_blank" rel="noopener" href="https://space.bilibili.com/33807709">https://space.bilibili.com/33807709</a></li>
</ul>
<h3 id="前言3-第1章课程内容提纲"><a class="markdownIt-Anchor" href="#前言3-第1章课程内容提纲"></a> [前言3]-第1章：课程内容提纲</h3>
<hr />
<blockquote>
<p>讲解整个Flink 框架基础课程【第1章】内容：主要包括如何内容：</p>
</blockquote>
<ul>
<li>
<p>1）、Flink 框架概述</p>
<ul>
<li>发展史、功能、特性及生态栈，包括扩展阅读新知识</li>
</ul>
</li>
<li>
<p>2）、Flink 安装部署==（重点，必须掌握）==</p>
<ul>
<li><a href="">运行架构原理</a></li>
<li>Standalone 集群部署：伪分布式集群（本地集群）、完全分布式集群和HA高可用集群</li>
<li><a href="">Flink on YARN：三种方式（Session 会话模式、Job 分离模式、Application应用模式）</a></li>
</ul>
</li>
<li>
<p>3）、<code>Flink 入门案例（掌握）</code></p>
<ul>
<li><a href="">大数据分析框架经典案例：词频统计WordCount</a></li>
<li>批<code>Batch</code>处理：词频统计WordCount，类似SparkCore中词频统计</li>
<li>流<code>Stream</code>计算：词频统计WordCount</li>
<li>打包提交运行集群<code>：命令行方式提交</code>和<code>UI界面方式提交</code></li>
</ul>
</li>
</ul>
<blockquote>
<p>本章学习目标如下：</p>
</blockquote>
<p><img src="1633392846884.png" alt="1633392846884" /></p>
<h2 id="第一部分flink-框架概述3个小节"><a class="markdownIt-Anchor" href="#第一部分flink-框架概述3个小节"></a> 第一部分：Flink 框架概述【3个小节】</h2>
<h3 id="01-理解-flink-概述之官方定义"><a class="markdownIt-Anchor" href="#01-理解-flink-概述之官方定义"></a> 01-[理解]-Flink 概述之官方定义</h3>
<hr />
<p>​																Apache Flink 官网：<a target="_blank" rel="noopener" href="https://flink.apache.org/">https://flink.apache.org/</a></p>
<blockquote>
<p>​			<a href="">Apache Flink 是一个开源的、基于流的、有状态的计算框架。它是分布式地执行的，具备低延迟、高吞吐的优秀性能，并且非常擅长处理有状态的复杂计算逻辑场景。</a></p>
</blockquote>
<p><img src="1614734097803.png" alt="" /></p>
<blockquote>
<p>官方定义：<mark><strong>Apache Flink is a framework and distributed processing engine for stateful computations over <em>unbounded and bounded</em> data streams.</strong></mark></p>
</blockquote>
<ul>
<li>
<p>1）、计算框架：类似MapReduce框架，分析数据</p>
</li>
<li>
<p>2）、分布式计算框架</p>
<ul>
<li>分析处理数据时，可以启动多个任务Task，同时并行处理</li>
<li><a href="">分布式计算思想：分而治之，先分，后合</a></li>
</ul>
</li>
<li>
<p>3）、建立在==数据流（DataStream）==之上状态计算框架</p>
<ul>
<li>
<p>处理的数据为<code>数据流（DataStream）</code></p>
</li>
<li>
<p>在Flink框架中，将所有数据认为是数据流DataStream</p>
<p><img src="bounded-unbounded.png" alt="" /></p>
<ul>
<li>静态数据：<mark>Bounded Data Stream</mark>，<strong>有界数据流</strong></li>
<li>动态数据：<mark>Unbounded Data Stream</mark>，<strong>无界数据流，流式数据</strong></li>
</ul>
</li>
</ul>
<blockquote>
<p><a href="">Flink 计算引擎，针对流数据进行处理，来一条数据处理一条数据，划分为有界流和无界流。</a></p>
</blockquote>
</li>
<li>
<p>4）、状态计算：<code>Stateful Computions</code></p>
<ul>
<li>Flink程序在处理数据时（流式计算，针对无界流数据处理），记录状态State信息</li>
<li>比如以词频统计为例，记录每个单词词频；</li>
</ul>
</li>
</ul>
<p><img src="1644719616023.png" alt="1644719616023" /></p>
<blockquote>
<p>​			Apache Flink 是 Apache 开源软件基金会的一个<strong>顶级项目</strong>，和许多 Apache 顶级项目一样，如 Spark 起源于 UC 伯克利的实验室， Flink 也是起源于非常有名的大学的实验室——<strong>柏林工业大学实验室</strong>。</p>
</blockquote>
<p><img src="1629899621701.png" alt="" /></p>
<blockquote>
<p>​			Flink 诞生于欧洲的一个大数据研究项目 <code>StratoSphere</code>。早期，Flink 是做 Batch 计算的，但是在 2014 年， StratoSphere 里面的核心成员孵化出 Flink，同年将 Flink 捐赠 Apache，并在后来成为 Apache 的顶级大数据项目，同时 Flink计算的主流方向被定位为 Streaming， 即<strong>用流式计算来做所有大数据的计算</strong>，这就是 Flink 技术诞生的背景。</p>
</blockquote>
<p>​									<a href="">项目最初的名称为 Stratosphere，目标是要让大数据的处理看起来更加地简洁。</a></p>
<p><img src="1614735779720.png" alt="" /></p>
<blockquote>
<p>​			由于 Flink 项目吸引了非常多贡献者参与，活跃度等方面也都非常优秀，它<strong>在 2014 年 12 月成为了 Apache 的顶级项目</strong>。成为顶级项目之后，它在一个月之后发布了<strong>第一个 Release 版本 Flink 0.8.0</strong>。在此之后，Flink 基本保持 4 个月 1 个版本的节奏，发展到今天。</p>
</blockquote>
<p><img src="1614736092102.png" alt="" /></p>
<blockquote>
<p>​		当阿里收购Flink母公司以后，大力推广Flink使用，以及将内部<code>Blink</code>框架功能与Apache Flink框架整合，陆续发布：Flink 1.9.0 版本，Flink 1.10.0（稳当），Flink 1.11.0，Flink <code>1.12.0</code>（里程碑版本）。</p>
</blockquote>
<p><img src="1633525384745.png" alt="1633525384745" /></p>
<blockquote>
<p>​		Flink 框架尤其在2019年和2020年发展比较迅速，版本迭代更加频繁，尤其2020年底发布<code>Flink 1.12</code>版本，<strong>里程碑版本</strong>，<code>流批一体化编程模式</code>，并且<code>Flink Table API和SQL成熟稳定</code>，可以用于实际生产环境。</p>
</blockquote>
<p><img src="1614734865437.png" alt="" /></p>
<blockquote>
<p>当Flink框架出现，并且成熟以后，未来的数据分析处理：<strong>实时处理分析</strong>，Flink框架首选。</p>
</blockquote>
<p><img src="1614734748662.png" alt="" /></p>
<h3 id="02-掌握-flink-概述之流式计算思想"><a class="markdownIt-Anchor" href="#02-掌握-flink-概述之流式计算思想"></a> 02-[掌握]-Flink 概述之流式计算思想</h3>
<hr />
<blockquote>
<p><a href="">Flink 流式计算程序，来一条数据处理一条数据，每次处理一条数据，真正流计算。</a></p>
</blockquote>
<p><img src="1633525474698.png" alt="1633525474698" /></p>
<blockquote>
<p>Flink 框架进行流式计算时，整个流程分为：<a href="">数据源Source、数据转换Transformation和数据接收器Sink</a>。</p>
</blockquote>
<figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">第一步、从数据源获取数据时，将数据封装到数据流</span><br><span class="line">	DataStream</span><br><span class="line">	实际项目，主要从Kafka 消息队列中消费数据</span><br><span class="line">	</span><br><span class="line">第二步、数据处理时，调用DataStream方法</span><br><span class="line">	DataStream<span class="comment">#transformation</span></span><br><span class="line">	类似RDD中转换算子，比如map、flatMap、filter等等</span><br><span class="line"></span><br><span class="line">第三步、将分析数据输出到外部存储</span><br><span class="line">	DataStream<span class="comment">#sink</span></span><br><span class="line">	类似RDD中触发/输出算子，比如foreach.....</span><br></pre></td></tr></table></figure>
<blockquote>
<p>Flink应用程序进行<strong>分布式</strong>流式计算时，如何做到<a href="">并行计算</a>，如下图所示：</p>
</blockquote>
<p><img src="1633525569335.png" alt="1633525569335" /></p>
<p>​</p>
<p>​					对于Flink框架来说，每个Job运行时，<strong>在处理第一条数据之前，首先需要获取资源，运行Task任务，准备数据到达，当数据到达时，一个个数据处理</strong>。</p>
<blockquote>
<ul>
<li><strong>算子 Operator</strong> ：<code>无论是从数据源Source加载数据，还是调用方法转换Transformation处理数据，到最后数据终端Sink输出，都称为Operator</code>，分为：<code>Source Operator、Transformation Operator和Sink Operator</code> 。</li>
<li><strong>流 Stream</strong>：数据从一个Operator流向另一个Operator；</li>
</ul>
</blockquote>
<p><img src="1629901961306.png" alt="" /></p>
<blockquote>
<p>​			每个算子Operator可以设置并行度（<strong>Parallelism</strong>），假设【<code>Source</code>】、【<code>map()</code>】及【<code>keyBy()/window()/apply()</code>】三个Operator并行度设置为<strong>2</strong>，【<code>Sink</code>】Operator并行的设置为<strong>1</strong>，形成如下示意图：</p>
</blockquote>
<p><img src="1629901989018.png" alt="" /></p>
<blockquote>
<p>Flink 流式计算引擎特点：</p>
</blockquote>
<p><img src="1633397327645.png" alt="1633397327645" /></p>
<h3 id="03-了解-flink-概述之应用场景"><a class="markdownIt-Anchor" href="#03-了解-flink-概述之应用场景"></a> 03-[了解]-Flink 概述之应用场景</h3>
<hr />
<blockquote>
<p>Apache Flink在阿里巴巴主要应用场景如下四类：<a href="">实时数仓、实时监控、实时报表、流数据分析	</a></p>
</blockquote>
<p><img src="1614737695168.png" alt="" /></p>
<blockquote>
<p>官方提出三个方面，Flink框架应用场景：</p>
</blockquote>
<p><img src="1633399009714.png" alt="1633399009714" /></p>
<ul>
<li>1）、事件驱动型应用：<code>Event-driven Applications</code></li>
</ul>
<hr />
<p>​		<a href="">事件驱动表示一个事件会触发另一个或者很多个后续的事件，然后这一系列事件会形成一些信息，基于这些信息需要做一定的处理。</a></p>
<p><img src="1629903243124.png" alt="" /></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">1、在社交场景下，以【微博】为例，当点击了一个关注之后，被关注人的粉丝数就会发生变化。之后如果被关注的人发了一条微博，关注他的粉丝也会收到消息通知，这是一个典型的事件驱动。</span><br><span class="line"></span><br><span class="line">2、在网购的场景底下，如用户给商品做评价，这些评价一方面会影响店铺的星级，另外一方面有恶意差评的检测。此外，用户通过点击信息流，也可看到商品派送或其他状态，这些都可能触发后续的一系列事件。</span><br><span class="line"></span><br><span class="line">3、金融反欺诈的场景，诈骗者通过短信诈骗，然后在取款机窃取别人的钱财。在这种场景底下，我们通过摄像头拍摄后，迅速反应识别出来，然后对犯罪的行为进  行相应的处理，一个典型的事件驱动型应用。</span><br></pre></td></tr></table></figure>
<blockquote>
<p>​		<strong>总结一下</strong>，事件驱动型应用是一类具有<strong>状态的应用</strong>，会根据事件流中的事件触发计算、更新状态或进行外部系统操作。事件驱动型应用常见于实时计算业务中，比如：<strong>实时推荐，金融反欺诈，实时规则预警</strong>等。</p>
</blockquote>
<ul>
<li>2）、数据分析型应用：<code>Data Analytics Applications</code></li>
</ul>
<hr />
<p><img src="1629903504528.png" alt="" /></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">如双 11 成交额实时汇总，包括PV、UV 的统计；包括上方图中所示，是 Apache 开源软件在全世界不同地区的一个下载量，其实也是一个信息的汇总。</span><br></pre></td></tr></table></figure>
<p><img src="1629903674802.png" alt="" /></p>
<p>​		如上图所示，以双 11 为例，在 2020 年天猫双 11 购物节，阿里基于 Flink 的实时计算平台每秒处理的消息数达到了 40 亿条，数据体量达到 7TB，订单创建数达到 58 万/秒，计算规模也超过了 150 万核。</p>
<blockquote>
<p>可以看到，这些应用的场景体量很大且对于实时性要求非常高 ，这也 是Apache Flink 非常擅长的场景。</p>
</blockquote>
<ul>
<li>3）、数据管道型应用 (ETL)，<code>Data Pipeline Applications</code></li>
</ul>
<hr />
<blockquote>
<p>ETL（Extract-Transform-Load）是从数据源抽取/转换/加载/数据至目的端的过程。</p>
</blockquote>
<p><img src="1629903804060.png" alt="" /></p>
<ul>
<li>传统的 ETL 使用离线处理，经常做的是小时级别或者天级别的 ETL。</li>
<li>但是，随着大数据处理呈现实时化趋势，也会有实时数仓的需求，要求在分钟级或者秒级就能够对数据进行更新，从而进行及时的查询，能够看到实时的指标，然后做更实时的判断和分析。</li>
</ul>
<p><img src="1633489044621.png" alt="1633489044621" /></p>
<blockquote>
<p>在以上场景底下，Flink 能够最大限度地满足实时化的需求。</p>
</blockquote>
<p><img src="1629903836486.png" alt="" /></p>
<h2 id="第二部分flink-安装部署9个小节"><a class="markdownIt-Anchor" href="#第二部分flink-安装部署9个小节"></a> 第二部分：Flink 安装部署【9个小节】</h2>
<h3 id="04-掌握-安装部署之flink-cluster-架构"><a class="markdownIt-Anchor" href="#04-掌握-安装部署之flink-cluster-架构"></a> 04-[掌握]-安装部署之Flink Cluster 架构</h3>
<hr />
<blockquote>
<p>Flink Runtime运行时架构组成：<mark><strong>JobManager（主节点</strong>）和<strong>TaskManager<code>s</code>（从节点）</strong></mark>。</p>
</blockquote>
<p><a target="_blank" rel="noopener" href="https://nightlies.apache.org/flink/flink-docs-release-1.13/docs/concepts/flink-architecture/">https://nightlies.apache.org/flink/flink-docs-release-1.13/docs/concepts/flink-architecture/</a></p>
<p><img src="1633412578726.png" alt="1633412578726" /></p>
<ul>
<li>
<p>1）、<mark><strong>JobManager</strong></mark>：主节点Master，<strong>为每个Flink Job分配资源，管理和监控Job运行</strong>。</p>
<ul>
<li>主要负责调度 Flink Job 并协调 Task 做 checkpoint；</li>
<li>从 Client 处接收到 Job 和JAR 包等资源后，会生成优化后的执行计划，并以 Task 为单元调度到各个 TaskManager去执行；</li>
</ul>
</li>
<li>
<p>2）、<mark><strong>TaskManager</strong></mark>：从节点Workers，调度每个Job中Task任务执行，及负责Task监控和容错等。</p>
<ul>
<li>在启动的时候设置：<code>Slot 槽位数（资源槽）</code>，每个 slot 能启动 Task，其中Task 为线程。</li>
</ul>
</li>
</ul>
<p><img src="1633525750169.png" alt="1633525750169" /></p>
<blockquote>
<p><mark><strong>Flink Client</strong></mark>：提交应用程序，给主节点JobManager</p>
<ul>
<li>Client 为提交 Job 的客户端，可以是运行在任何机器上（与 JobManager 环境连通即可）。</li>
</ul>
</blockquote>
<p><img src="1633412935980.png" alt="1633412935980" /></p>
<blockquote>
<p>Flink支持多种安装运行模式，可以将Flink程序运行在很多地方：</p>
</blockquote>
<p><img src="1648421643678.png" alt="1648421643678" /></p>
<ul>
<li>
<p>第一、<code>Local 模式</code></p>
<p><a href="">在Windows系统上IDEA集成开发环境编写Flink 代码程序，直接运行测试即为本地测试</a></p>
<ul>
<li>
<p>适用于本地开发和测试环境，占用的资源较少，部署简单</p>
</li>
<li>
<p>本地模式LocalMode：JobManager和TaskManager运行在<mark>同一个JVM进程</mark>中</p>
</li>
</ul>
<p><img src="1633414183605.png" alt="1633414183605" /></p>
</li>
<li>
<p>第二、<code>Standalone 模式</code></p>
<p><a href="">将JobManager和TaskManagers直接运行机器上，称为Standalone集群，Flink框架自己集群</a></p>
<ul>
<li>
<p>可以在测试环境功能验证完毕到版本发布的时候使用，进行性能验证</p>
<p><a target="_blank" rel="noopener" href="https://nightlies.apache.org/flink/flink-docs-release-1.13/docs/deployment/resource-providers/standalone/overview/">https://nightlies.apache.org/flink/flink-docs-release-1.13/docs/deployment/resource-providers/standalone/overview/</a></p>
</li>
<li>
<p>高可用HA：Standalone Cluster HA</p>
<p><a target="_blank" rel="noopener" href="https://nightlies.apache.org/flink/flink-docs-release-1.13/docs/deployment/ha/zookeeper_ha/">https://nightlies.apache.org/flink/flink-docs-release-1.13/docs/deployment/ha/zookeeper_ha/</a></p>
</li>
</ul>
</li>
<li>
<p>第三、<code>Flink On Yarn 模式</code></p>
<p><a href="">将JobManager和TaskManagers运行在NodeManage的Container容器中，称为Flink on YARN。</a></p>
<ul>
<li>
<p>Flink使用YARN进行调度</p>
<p><a target="_blank" rel="noopener" href="https://nightlies.apache.org/flink/flink-docs-release-1.13/docs/deployment/resource-providers/yarn/">https://nightlies.apache.org/flink/flink-docs-release-1.13/docs/deployment/resource-providers/yarn/</a></p>
</li>
</ul>
</li>
<li>
<p>第四、<code>K8s 模式</code></p>
<p><a href="">将JobManager和TaskManagers运行在K8s容器Container中。</a></p>
<ul>
<li>
<p>由于Flink使用的无状态模式，只需要kubernetes提供计算资源即可。会是Flink以后运行的主流方式，可以起到节约硬件资源和便于管理的效果。</p>
<p><a target="_blank" rel="noopener" href="https://nightlies.apache.org/flink/flink-docs-release-1.13/docs/deployment/resource-providers/native_kubernetes/">https://nightlies.apache.org/flink/flink-docs-release-1.13/docs/deployment/resource-providers/native_kubernetes/</a></p>
</li>
</ul>
</li>
</ul>
<figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Apache Flink 框架软件下载：</span></span><br><span class="line">	https://flink.apache.org/downloads.html</span><br><span class="line">	https://archive.apache.org/dist/flink/</span><br><span class="line">	</span><br><span class="line"><span class="comment"># Aapche Flink 官方文档：</span></span><br><span class="line">	https://ci.apache.org/projects/flink/flink-docs-release-1.13/</span><br></pre></td></tr></table></figure>
<h3 id="05-理解-安装部署之本地集群"><a class="markdownIt-Anchor" href="#05-理解-安装部署之本地集群"></a> 05-[理解]-安装部署之本地集群</h3>
<hr />
<blockquote>
<p><a href="">针对Flink框架来说，进程分别为<code>JobManager</code>（主节点，管理者）和<code>TaskManager</code>（从节点，干活着）</a></p>
</blockquote>
<p><img src="1614741619007.png" alt="" /></p>
<p>Local Cluster 本地集群：<strong>将不同进程运行在同一台机器上，只有一台机器</strong>。</p>
<blockquote>
<p>提交Flink Job运行原理如下：</p>
</blockquote>
<p><img src="1614741637978.png" alt="" /></p>
<ol>
<li>Flink程序（比如jar包）由<code>JobClient</code>进行提交；</li>
<li>JobClient将作业提交给<code>JobManager</code>；</li>
<li>JobManager负责<strong>协调资源分配和作业执行</strong>。资源分配完成后，任务将提交给相应的<code>TaskManager</code>；</li>
<li>TaskManager<strong>启动一个线程以开始执行</strong>。TaskManager会向JobManager报告状态更改，如开始执行，正在进行或已完成；</li>
<li>作业执行完成后，结果将发送回客户端(JobClient)；</li>
</ol>
<blockquote>
<ul>
<li>1）、上传软件及解压</li>
</ul>
</blockquote>
<figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="section">[root@node1 ~]</span><span class="comment"># cd /export/software/</span></span><br><span class="line"><span class="section">[root@node1 software]</span><span class="comment"># rz</span></span><br><span class="line">	上传软件包：flink-1.13.1-bin-scala_2.11.tgz</span><br><span class="line">	</span><br><span class="line"><span class="section">[root@node1 software]</span><span class="comment"># chmod u+x flink-1.13.1-bin-scala_2.11.tgz</span></span><br><span class="line"><span class="section">[root@node1 software]</span><span class="comment"># tar -zxf flink-1.13.1-bin-scala_2.11.tgz -C /export/server/	</span></span><br><span class="line"></span><br><span class="line"><span class="section">[root@node1 ~]</span><span class="comment"># cd /export/server/</span></span><br><span class="line"><span class="section">[root@node1 server]</span><span class="comment"># chown -R root:root flink-1.13.1</span></span><br><span class="line"><span class="section">[root@node1 server]</span><span class="comment"># mv flink-1.13.1 flink-local</span></span><br></pre></td></tr></table></figure>
<p><a href="">当将Flink软件压缩包解压以后，<code>默认配置，就是本地集群配置，可以直接启动服务即可</code></a></p>
<figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 目录结构</span></span><br><span class="line"><span class="section">[root@node1 server]</span><span class="comment"># cd flink-local/</span></span><br><span class="line"><span class="section">[root@node1 flink-local]</span><span class="comment"># ll</span></span><br><span class="line">total 480</span><br><span class="line">drwxrwxr-x  2 root root   4096 May 25 20:36 bin</span><br><span class="line">drwxrwxr-x  2 root root    263 May 25 20:36 conf</span><br><span class="line">drwxrwxr-x  7 root root     76 May 25 20:36 examples</span><br><span class="line">drwxrwxr-x  2 root root   4096 May 25 20:36 lib</span><br><span class="line">-rw-r--r--  1 root root  11357 Oct 29  2019 LICENSE</span><br><span class="line">drwxrwxr-x  2 root root   4096 May 25 20:37 licenses</span><br><span class="line">drwxr-xr-x  2 root root      6 Oct  5 10:25 log</span><br><span class="line">-rw-rw-r--  1 root root 455180 May 25 20:37 NOTICE</span><br><span class="line">drwxrwxr-x  3 root root   4096 May 25 20:36 opt</span><br><span class="line">drwxrwxr-x 10 root root    210 May 25 20:36 plugins</span><br><span class="line">-rw-r--r--  1 root root   1309 Jan 30  2021 README.txt</span><br></pre></td></tr></table></figure>
<blockquote>
<ul>
<li>2）、启动Flink本地集群</li>
</ul>
</blockquote>
<figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="section">[root@node1 ~]</span><span class="comment"># cd /export/server/flink-local/</span></span><br><span class="line"></span><br><span class="line"><span class="section">[root@node1 flink-local]</span><span class="comment"># bin/start-cluster.sh</span></span><br><span class="line"></span><br><span class="line"><span class="section">[root@node1 flink-local]</span><span class="comment"># jps</span></span><br><span class="line">3504 TaskManagerRunner</span><br><span class="line">3239 StandaloneSessionClusterEntrypoint</span><br><span class="line">3559 Jps</span><br></pre></td></tr></table></figure>
<blockquote>
<ul>
<li>3）、访问Flink的Web UI：<a target="_blank" rel="noopener" href="http://node1.itcast.cn:8081/#/overview">http://node1.itcast.cn:8081/#/overview</a></li>
</ul>
</blockquote>
<p><img src="1633419163511.png" alt="1633419163511" /></p>
<blockquote>
<p>​		<code>slot</code>在Flink里面可以认为是资源组，Flink是通过<strong>将任务（Task）分成子任务（SubTask）<strong>并且将这些子任务分配到</strong>slot</strong>来并行执行程序。</p>
</blockquote>
<p><img src="1628910791520.png" alt="" /></p>
<p>​	<a href="">Slot 封装Task运行资源，可以认为Contanier容器，</a>同一个Slot资源槽中可以运行不同类型子任务SubTask，相当于“猪槽，可以被多个PIG吃食。”</p>
<blockquote>
<ul>
<li>4）、测试完成以后，关闭本地集群</li>
</ul>
</blockquote>
<figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="section">[root@node1 ~]</span><span class="comment"># /export/server/flink-local/bin/stop-cluster.sh </span></span><br></pre></td></tr></table></figure>
<blockquote>
<p>当本地集群启动以后，运行Flink应用程序，分别运行<strong>流计算和批处理 词频统计</strong>。</p>
</blockquote>
<ul>
<li><code>flink</code> 脚本命令提交运行jar包程序，具体命令使用说明如下：</li>
</ul>
<figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br></pre></td><td class="code"><pre><span class="line"><span class="section">[root@node1 ~]</span><span class="comment"># cd /export/server/flink-local/</span></span><br><span class="line"><span class="section">[root@node1 flink-local]</span><span class="comment"># bin/flink run --help</span></span><br><span class="line"></span><br><span class="line">Action &quot;run&quot; compiles and runs a program.</span><br><span class="line"></span><br><span class="line">  Syntax: run <span class="section">[OPTIONS]</span> &lt;jar-file&gt; &lt;arguments&gt;</span><br><span class="line">  &quot;run&quot; action options:</span><br><span class="line">     -c,--class &lt;classname&gt;               Class with the program entry point</span><br><span class="line">                                          (&quot;main()&quot; method). Only needed if the</span><br><span class="line">                                          JAR file does not specify the class in</span><br><span class="line">                                          its manifest.</span><br><span class="line">     -C,--classpath &lt;url&gt;                 Adds a URL to each user code</span><br><span class="line">                                          classloader  on all nodes in the</span><br><span class="line">                                          cluster. The paths must specify a</span><br><span class="line">                                          protocol (e.g. file://) and be</span><br><span class="line">                                          accessible on all nodes (e.g. by means</span><br><span class="line">                                          of a NFS share). You can use this</span><br><span class="line">                                          option multiple times for specifying</span><br><span class="line">                                          more than one URL. The protocol must</span><br><span class="line">                                          be supported by the &#123;@link</span><br><span class="line">                                          java.net.URLClassLoader&#125;.</span><br><span class="line">     -d,--detached                        If present, runs the job in detached</span><br><span class="line">                                          mode</span><br><span class="line">     -p,--parallelism &lt;parallelism&gt;       The parallelism with which to run the</span><br><span class="line">                                          program. Optional flag to override the</span><br><span class="line">                                          default value specified in the</span><br><span class="line">                                          configuration.</span><br><span class="line"></span><br><span class="line">  Options for Generic CLI mode:</span><br><span class="line">     -D &lt;<span class="attr">property</span>=value&gt;   Allows specifying multiple generic configuration</span><br><span class="line">                           options. The available options can be found at</span><br><span class="line">                           https://ci.apache.org/projects/flink/flink-docs-stabl</span><br><span class="line">                           e/ops/config.html</span><br><span class="line">     -t,--target &lt;arg&gt;     The deployment target for the given application,</span><br><span class="line">                           which is equivalent to the &quot;execution.target&quot; config</span><br><span class="line">                           option. For the &quot;run&quot; action the currently available</span><br><span class="line">                           targets are: &quot;remote&quot;, &quot;local&quot;, &quot;kubernetes-session&quot;,</span><br><span class="line">                           &quot;yarn-per-job&quot;, &quot;yarn-session&quot;. For the</span><br><span class="line">                           &quot;run-application&quot; action the currently available</span><br><span class="line">                           targets are: &quot;kubernetes-application&quot;.</span><br><span class="line"></span><br><span class="line">  Options for yarn-cluster mode:</span><br><span class="line">     -m,--jobmanager &lt;arg&gt;            Set to yarn-cluster to use YARN execution</span><br><span class="line">                                      mode.</span><br><span class="line">     -yid,--yarnapplicationId &lt;arg&gt;   Attach to running YARN session</span><br><span class="line">     -z,--zookeeperNamespace &lt;arg&gt;    Namespace to create the Zookeeper</span><br><span class="line">                                      sub-paths for high availability mode</span><br><span class="line"></span><br><span class="line">  Options for default mode:</span><br><span class="line">     -D &lt;<span class="attr">property</span>=value&gt;             Allows specifying multiple generic</span><br><span class="line">                                     configuration options. The available</span><br><span class="line">                                     options can be found at</span><br><span class="line">                                     https://ci.apache.org/projects/flink/flink-</span><br><span class="line">                                     docs-stable/ops/config.html</span><br><span class="line">     -m,--jobmanager &lt;arg&gt;           Address of the JobManager to which to</span><br><span class="line">                                     connect. Use this flag to connect to a</span><br><span class="line">                                     different JobManager than the one specified</span><br><span class="line">                                     in the configuration. Attention: This</span><br><span class="line">                                     option is respected only if the</span><br><span class="line">                                     high-availability configuration is NONE.</span><br><span class="line">     -z,--zookeeperNamespace &lt;arg&gt;   Namespace to create the Zookeeper sub-paths</span><br><span class="line">                                     for high availability mode</span><br></pre></td></tr></table></figure>
<blockquote>
<ul>
<li>1）、流计算：WordCount词频统计，<a href="">运行流式计算程序，从TCP Socket 读取数据，进行词频统计。</a></li>
</ul>
</blockquote>
<p><img src="1633419832998.png" alt="1633419832998" /></p>
<figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 开启1个终端</span></span><br><span class="line">nc -lk 9999</span><br><span class="line"></span><br><span class="line"><span class="comment"># 上传jar【StreamWordCount.jar】包至/export/server/flink-local目录</span></span><br><span class="line">cd /export/server/flink-local</span><br><span class="line">rz</span><br><span class="line"></span><br><span class="line"><span class="comment"># 再开启1个终端，运行流式应用</span></span><br><span class="line">/export/server/flink-local/bin/flink run \</span><br><span class="line">--class cn.itcast.flink.StreamWordCount \</span><br><span class="line">/export/server/flink-local/StreamWordCount.jar \</span><br><span class="line">--host node1.itcast.cn --port 9999</span><br></pre></td></tr></table></figure>
<p><img src="1633420098242.png" alt="1633420098242" /></p>
<blockquote>
<ul>
<li>2）、监控页面查看日志信息数据</li>
</ul>
</blockquote>
<p><img src="1633420117287.png" alt="1633420117287" /></p>
<p><img src="1633420180093.png" alt="1633420180093" /></p>
<blockquote>
<p>查看TaskManager日志，每条数据处理结果：</p>
</blockquote>
<p><img src="1633420246834.png" alt="1633420246834" /></p>
<blockquote>
<p>执行官方示例Example，<strong>读取文本文件数据，进行词频统计WordCount，将结果打印控制台或文件</strong>。</p>
</blockquote>
<p><img src="1633420700445.png" alt="1633420700445" /></p>
<blockquote>
<p>1）、准备文件<code>/root/words.txt</code></p>
</blockquote>
<figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="section">[root@node1 ~]</span><span class="comment"># vim /root/words.txt</span></span><br><span class="line">添加数据</span><br><span class="line">spark python spark hive spark hive</span><br><span class="line">python spark hive spark python</span><br><span class="line">mapreduce spark hadoop hdfs hadoop spark</span><br><span class="line">hive mapreduce</span><br></pre></td></tr></table></figure>
<blockquote>
<ul>
<li>2）批处理，执行如下命令</li>
</ul>
</blockquote>
<figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 指定处理数据文件，通过参数 --input 传递</span></span><br><span class="line">/export/server/flink-local/bin/flink run \</span><br><span class="line">/export/server/flink-local/examples/batch/WordCount.jar \</span><br><span class="line">--input /root/words.txt</span><br></pre></td></tr></table></figure>
<p><img src="1633420505322.png" alt="1633420505322" /></p>
<figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 指定处理数据文件和输出数据目录，分别通过--input 和 --output 传递参数值</span></span><br><span class="line">/export/server/flink-local/bin/flink run \</span><br><span class="line">/export/server/flink-local/examples/batch/WordCount.jar \</span><br><span class="line">--input /root/words.txt --output /root/out.txt</span><br></pre></td></tr></table></figure>
<p><img src="1633420612315.png" alt="1633420612315" /></p>
<h3 id="06-理解-安装部署之standalone-集群"><a class="markdownIt-Anchor" href="#06-理解-安装部署之standalone-集群"></a> 06-[理解]-安装部署之Standalone 集群</h3>
<hr />
<blockquote>
<p><strong>Flink Standalone集群</strong>，类似Hadoop YARN集群，<mark>管理集群资源和分配资源给Flink Job运行任务Task</mark>。</p>
</blockquote>
<p><img src="1644670949884.png" alt="1644670949884" /></p>
<ol>
<li>Client客户端提交任务给JobManager；</li>
<li>JobManager负责申请任务运行所需要的资源并管理任务和资源；</li>
<li>JobManager分发任务给TaskManager执行；</li>
<li>TaskManager定期向JobManager汇报状态；</li>
</ol>
<blockquote>
<ul>
<li>0）、集群规划：</li>
</ul>
</blockquote>
<p><img src="1614743548233.png" alt="" /></p>
<blockquote>
<ul>
<li>1）、上传软件及解压</li>
</ul>
</blockquote>
<figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="section">[root@node1 ~]</span><span class="comment"># cd /export/software/</span></span><br><span class="line"><span class="section">[root@node1 software]</span><span class="comment"># rz</span></span><br><span class="line">	上传软件包：flink-1.13.1-bin-scala_2.11.tgz</span><br><span class="line">	</span><br><span class="line"><span class="section">[root@node1 software]</span><span class="comment"># chmod u+x flink-1.13.1-bin-scala_2.11.tgz</span></span><br><span class="line"><span class="section">[root@node1 software]</span><span class="comment"># tar -zxf flink-1.13.1-bin-scala_2.11.tgz -C /export/server/	</span></span><br><span class="line"></span><br><span class="line"><span class="section">[root@node1 ~]</span><span class="comment"># cd /export/server/</span></span><br><span class="line"><span class="section">[root@node1 server]</span><span class="comment"># chown -R root:root flink-1.13.1</span></span><br><span class="line"><span class="section">[root@node1 server]</span><span class="comment"># mv flink-1.13.1 flink-standalone</span></span><br></pre></td></tr></table></figure>
<blockquote>
<ul>
<li>2）、修改<code>flink-conf.yaml</code></li>
</ul>
</blockquote>
<figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">vim /export/server/flink-standalone/conf/flink-conf.yaml</span><br><span class="line">修改内容：33行内容</span><br><span class="line">	jobmanager.rpc.address: node1.itcast.cn</span><br></pre></td></tr></table></figure>
<blockquote>
<ul>
<li>3）、修改<code>masters</code></li>
</ul>
</blockquote>
<figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">vim /export/server/flink-standalone/conf/masters</span><br><span class="line">修改内容：	</span><br><span class="line">	node1.itcast.cn:8081</span><br></pre></td></tr></table></figure>
<blockquote>
<ul>
<li>4）、修改<code>workers</code></li>
</ul>
</blockquote>
<figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">vim /export/server/flink-standalone/conf/workers</span><br><span class="line">修改内容：	</span><br><span class="line">    node1.itcast.cn</span><br><span class="line">    node2.itcast.cn</span><br><span class="line">    node3.itcast.cn</span><br></pre></td></tr></table></figure>
<blockquote>
<ul>
<li>5）、添加<code>HADOOP_CONF_DIR</code>环境变量(<strong>集群所有机器</strong>）</li>
</ul>
</blockquote>
<figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">vim /etc/profile</span><br><span class="line">	添加内容：</span><br><span class="line">	export <span class="attr">HADOOP_CONF_DIR</span>=/export/server/hadoop/etc/hadoop</span><br><span class="line"><span class="comment"># 执行生效</span></span><br><span class="line">source /etc/profile</span><br></pre></td></tr></table></figure>
<blockquote>
<ul>
<li>6）、将Flink依赖Hadoop 框架JAR包上传至<code>/export/server/flink-standalone/lib</code>目录</li>
</ul>
</blockquote>
<p><img src="1633421482610.png" alt="1633421482610" /></p>
<figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="section">[root@node1 ~]</span><span class="comment"># cd /export/server/flink-standalone/lib/</span></span><br><span class="line"></span><br><span class="line"><span class="section">[root@node1 lib]</span><span class="comment"># rz</span></span><br><span class="line">	commons-cli-1.4.jar</span><br><span class="line">	flink-shaded-hadoop-3-uber-3.1.1.7.2.1.0-327-9.0.jar</span><br></pre></td></tr></table></figure>
<blockquote>
<ul>
<li>7）、分发到集群其他机器</li>
</ul>
</blockquote>
<figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">scp -r /export/server/flink-standalone root@node2.itcast.cn:/export/server</span><br><span class="line"></span><br><span class="line">scp -r /export/server/flink-standalone root@node3.itcast.cn:/export/server</span><br></pre></td></tr></table></figure>
<p>​			接下来，启动服务进程，运行批处理程序：词频统计WordCount。</p>
<blockquote>
<ul>
<li>1）、启动HDFS集群，在<code>node1.itcast.cn</code>上执行如下命令</li>
</ul>
</blockquote>
<figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">start-dfs.sh</span><br></pre></td></tr></table></figure>
<p>​</p>
<blockquote>
<ul>
<li>2）、启动集群，执行如下命令</li>
</ul>
</blockquote>
<figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 一键启动所有服务JobManager和TaskManagers</span></span><br><span class="line"><span class="section">[root@node1 ~]</span><span class="comment"># /export/server/flink-standalone/bin/start-cluster.sh </span></span><br><span class="line">Starting cluster.</span><br><span class="line">Starting standalonesession daemon on host node1.itcast.cn.</span><br><span class="line">Starting taskexecutor daemon on host node1.itcast.cn.</span><br><span class="line">Starting taskexecutor daemon on host node2.itcast.cn.</span><br><span class="line">Starting taskexecutor daemon on host node3.itcast.cn.</span><br></pre></td></tr></table></figure>
<p><img src="1633421994734.png" alt="1633421994734" /></p>
<blockquote>
<ul>
<li>3）、访问Flink UI界面：<a target="_blank" rel="noopener" href="http://node1.itcast.cn:8081/#/overview">http://node1.itcast.cn:8081/#/overview</a></li>
</ul>
</blockquote>
<p><img src="1633422040826.png" alt="1633422040826" /></p>
<p><img src="1633422420531.png" alt="1633422420531" /></p>
<blockquote>
<ul>
<li>4）、执行官方测试案例</li>
</ul>
</blockquote>
<figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 准备测试数据</span></span><br><span class="line"><span class="section">[root@node1 ~]</span><span class="comment"># hdfs dfs -mkdir -p /wordcount/input/</span></span><br><span class="line"><span class="section">[root@node1 ~]</span><span class="comment"># hdfs dfs -put /root/words.txt /wordcount/input/</span></span><br></pre></td></tr></table></figure>
<p><img src="1633422301964.png" alt="1633422301964" /></p>
<figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 运行程序，使用--input指定处理数据文件路径</span></span><br><span class="line">/export/server/flink-standalone/bin/flink run \</span><br><span class="line">/export/server/flink-standalone/examples/batch/WordCount.jar \</span><br><span class="line">--input hdfs://node1.itcast.cn:8020/wordcount/input/words.txt</span><br></pre></td></tr></table></figure>
<p><img src="1633422457779.png" alt="1633422457779" /></p>
<figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 使用--output指定处理结果数据存储目录</span></span><br><span class="line">/export/server/flink-standalone/bin/flink run \</span><br><span class="line">/export/server/flink-standalone/examples/batch/WordCount.jar \</span><br><span class="line">--input hdfs://node1.itcast.cn:8020/wordcount/input/words.txt \</span><br><span class="line">--output hdfs://node1.itcast.cn:8020/wordcount/output/result</span><br><span class="line"></span><br><span class="line"><span class="section">[root@node1 ~]</span><span class="comment"># hdfs dfs -text /wordcount/output/result</span></span><br></pre></td></tr></table></figure>
<p><img src="1633422618479.png" alt="1633422618479" /></p>
<blockquote>
<ul>
<li>5）、关闭Standalone集群服务</li>
</ul>
</blockquote>
<figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 一键停止所有服务JobManager和TaskManagers</span></span><br><span class="line"><span class="section">[root@node1 ~]</span><span class="comment"># /export/server/flink-standalone/bin/stop-cluster.sh </span></span><br><span class="line">Stopping taskexecutor daemon (pid: 6600) on host node1.itcast.cn.</span><br><span class="line">Stopping taskexecutor daemon (pid: 3016) on host node2.itcast.cn.</span><br><span class="line">Stopping taskexecutor daemon (pid: 3034) on host node3.itcast.cn.</span><br><span class="line">Stopping standalonesession daemon (pid: 6295) on host node1.itcast.cn.</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<blockquote>
<p><strong>补充</strong>：Flink Standalone集群启动与停止，也可以逐一服务启动</p>
</blockquote>
<figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 每个服务单独启动</span></span><br><span class="line"><span class="comment"># 在node1.itcast.cn上启动</span></span><br><span class="line">/export/server/flink-standalone/bin/jobmanager.sh start</span><br><span class="line"><span class="comment"># 在node1.itcast.cn、node2.itcast.cn、node3.itcast.cn</span></span><br><span class="line">/export/server/flink-standalone/bin/taskmanager.sh start  <span class="comment"># 每台机器执行</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># ===============================================================</span></span><br><span class="line"><span class="comment"># 每个服务单独停止</span></span><br><span class="line"><span class="comment"># 在node1.itcast.cn上停止</span></span><br><span class="line">/export/server/flink-standalone/bin/jobmanager.sh stop</span><br><span class="line"><span class="comment"># 在node1.itcast.cn、node2.itcast.cn、node3.itcast.cn</span></span><br><span class="line">/export/server/flink-standalone/bin/taskmanager.sh stop </span><br></pre></td></tr></table></figure>
<h3 id="07-了解-安装部署之standalone-ha"><a class="markdownIt-Anchor" href="#07-了解-安装部署之standalone-ha"></a> 07-[了解]-安装部署之Standalone HA</h3>
<hr />
<blockquote>
<p>​			从Standalone架构图中，可发现JobManager存在<code>单点故障（SPOF</code>），一旦JobManager出现意外，整个集群无法工作。为了确保集群的高可用，需要搭建Flink的Standalone HA。</p>
</blockquote>
<p><img src="1644670949884.png" alt="1644670949884" /></p>
<blockquote>
<p>​		Flink Standalone HA集群，类似YARN HA 集群安装部署，可以<a href="">启动多个主机点JobManager，使用Zookeeper集群监控JobManagers转态，进行选举leader，实现自动故障转移。</a></p>
</blockquote>
<p><img src="1644670962923.png" alt="1644670962923" /></p>
<p>​			在 Zookeeper 的协助下，一个 Standalone的Flink集群会同时有多个活着的 JobManager，其中**只有一个处于Active工作状态，其他处于 Standby 状态。**当工作中的 JobManager 失去连接后(如宕机或 Crash)，Zookeeper 会从 Standby 中选一个新的 JobManager 来接管 Flink 集群。</p>
<blockquote>
<ul>
<li>1）、集群规划</li>
</ul>
</blockquote>
<p><img src="1614744989801.png" alt="" /></p>
<figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 在node1.itcast.cn上复制一份standalone</span></span><br><span class="line"><span class="section">[root@node1 ~]</span><span class="comment"># cd /export/server/</span></span><br><span class="line"><span class="section">[root@node1 server]</span><span class="comment"># cp -r flink-standalone flink-ha</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 删除日志文件</span></span><br><span class="line"><span class="section">[root@node1 ~]</span><span class="comment"># rm -rf /export/server/flink-ha/log/*</span></span><br></pre></td></tr></table></figure>
<blockquote>
<ul>
<li>2）、启动ZooKeeper，在<code>node1.itcast.cn</code>上启动</li>
</ul>
</blockquote>
<figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">start-zk.sh</span><br></pre></td></tr></table></figure>
<blockquote>
<ul>
<li>3）、启动HDFS，在<code>node1.itcast.cn</code>上启动，<strong>如果没有关闭，不用重启</strong></li>
</ul>
</blockquote>
<figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">start-dfs.sh</span><br></pre></td></tr></table></figure>
<blockquote>
<ul>
<li>4）、停止集群，在<code>node1.itacast.cn</code>操作，进行HA高可用配置</li>
</ul>
</blockquote>
<figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/export/server/flink-standalone/bin/stop-cluster.sh </span><br></pre></td></tr></table></figure>
<blockquote>
<ul>
<li>5）、修改<code>flink-conf.yaml</code>，在<code>node1.itacast.cn</code>操作</li>
</ul>
</blockquote>
<figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">vim /export/server/flink-ha/conf/flink-conf.yaml</span><br><span class="line">	修改内容：</span><br><span class="line">jobmanager.rpc.address: node1.itcast.cn	</span><br><span class="line"></span><br><span class="line">high-availability: zookeeper</span><br><span class="line">high-availability.storageDir: hdfs://node1.itcast.cn:8020/flink/ha/</span><br><span class="line">high-availability.zookeeper.quorum: node1.itcast.cn:2181,node2.itcast.cn:2181,node3.itcast.cn:2181</span><br><span class="line">high-availability.zookeeper.path.root: /flink</span><br><span class="line">high-availability.cluster-id: /cluster_standalone</span><br><span class="line"></span><br><span class="line">state.backend: filesystem</span><br><span class="line">state.backend.fs.checkpointdir: hdfs://node1.itcast.cn:8020/flink/checkpoints</span><br><span class="line">state.savepoints.dir: hdfs://node1.itcast.cn:8020/flink/savepoints</span><br></pre></td></tr></table></figure>
<blockquote>
<ul>
<li>6）、修改<code>masters</code>，在<code>node1.itacast.cn</code>操作</li>
</ul>
</blockquote>
<figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">vim /export/server/flink-ha/conf/masters</span><br><span class="line">	修改内容：</span><br><span class="line">	node1.itcast.cn:8081</span><br><span class="line">	node2.itcast.cn:8081</span><br></pre></td></tr></table></figure>
<blockquote>
<ul>
<li>7）、分发到集群其他机器，在<code>node1.itacast.cn</code>操作</li>
</ul>
</blockquote>
<figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">scp -r /export/server/flink-ha root@node2.itcast.cn:/export/server/</span><br><span class="line">scp -r /export/server/flink-ha root@node3.itcast.cn:/export/server/</span><br></pre></td></tr></table></figure>
<blockquote>
<ul>
<li>8）、修改<code>node2.itcast.cn</code>上的<code>flink-conf.yaml</code></li>
</ul>
</blockquote>
<figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="section">[root@node2 ~]</span><span class="comment"># vim /export/server/flink-ha/conf/flink-conf.yaml </span></span><br><span class="line">	修改内容：33 行</span><br><span class="line">	jobmanager.rpc.address: node2.itcast.cn   </span><br></pre></td></tr></table></figure>
<blockquote>
<ul>
<li>9）、重新启动Flink集群</li>
</ul>
</blockquote>
<figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># node1.itcast.cn和node2.itcast.cn上执行</span></span><br><span class="line">/export/server/flink-ha/bin/jobmanager.sh start</span><br><span class="line"></span><br><span class="line"><span class="comment"># node1.itcast.cn和node2.itcast.cn、node3.itcast.cn执行</span></span><br><span class="line">/export/server/flink-ha/bin/taskmanager.sh start  <span class="comment"># 每台机器执行</span></span><br></pre></td></tr></table></figure>
<p><img src="1633424157381.png" alt="1633424157381" /></p>
<p>​		运行批处理词频统计WordCount，在Standalone HA高可用集群上：</p>
<blockquote>
<ul>
<li>1）、访问WebUI</li>
</ul>
</blockquote>
<p><img src="1633424730324.png" alt="1633424730324" /></p>
<blockquote>
<ul>
<li>2）、执行批处理词频统计WordCount</li>
</ul>
</blockquote>
<figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">/export/server/flink-ha/bin/flink run \</span><br><span class="line">/export/server/flink-ha/examples/batch/WordCount.jar \</span><br><span class="line">--input hdfs://node1.itcast.cn:8020/wordcount/input/words.txt</span><br></pre></td></tr></table></figure>
<p><img src="1633424799351.png" alt="1633424799351" /></p>
<blockquote>
<ul>
<li>3）、kill掉其中一个master，再次运行批处理词频统计</li>
</ul>
</blockquote>
<figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">/export/server/flink-ha/bin/flink run \</span><br><span class="line">/export/server/flink-ha/examples/batch/WordCount.jar \</span><br><span class="line">--input hdfs://node1.itcast.cn:8020/wordcount/input/words.txt</span><br></pre></td></tr></table></figure>
<p><img src="1633424955842.png" alt="1633424955842" /></p>
<blockquote>
<p>查看node2.itcast.cn上JobManager监控页面：</p>
</blockquote>
<p><img src="1633425037238.png" alt="1633425037238" /></p>
<blockquote>
<ul>
<li>4）、关闭集群服务：Standalone 服务、Zookeeper 服务和HDFS服务</li>
</ul>
</blockquote>
<figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># JM和TMs服务(node2.itcast.cn)</span></span><br><span class="line">/export/server/flink-ha/bin/stop-cluster.sh</span><br><span class="line"></span><br><span class="line"><span class="comment"># Zookeeper服务（node1.itcast.cn)</span></span><br><span class="line">stop-zk.sh </span><br><span class="line"></span><br><span class="line"><span class="comment"># HDFS服务（node1.itcast.cn)</span></span><br><span class="line">stop-dfs.sh</span><br></pre></td></tr></table></figure>
<h3 id="08-掌握-flink-on-yarn之运行流程"><a class="markdownIt-Anchor" href="#08-掌握-flink-on-yarn之运行流程"></a> 08-[掌握]-Flink on YARN之运行流程</h3>
<hr />
<p>​			在一个企业中，为了<mark>最大化的利用集群资源</mark>，一般都会在一个集群中同时运行多种类型的Workload，因此 Flink 也支持在 Yarn 集群运行。</p>
<blockquote>
<p>为什么使用<code>Flink on Yarn或Spark on Yarn?</code></p>
</blockquote>
<ul>
<li>
<p>1）、Yarn的资源可以按需使用，提高集群的资源利用率</p>
</li>
<li>
<p>2）、Yarn的任务有优先级，根据优先级运行作业</p>
</li>
<li>
<p>3）、基于Yarn调度系统，能够自动化地处理各个角色的 Failover(容错)</p>
<p><code>当应用程序（MR、Spark、Flink）运行在YARN集群上时，可以实现容灾恢复。</code></p>
</li>
</ul>
<p><img src="1652166719519.png" alt="1652166719519" /></p>
<blockquote>
<p>Flink on YARN本质：<a href="">将JobManager和TaskManagers运行在YARN Contanier容器中</a>。</p>
</blockquote>
<p><img src="1633428933682.png" alt="1633428933682" /></p>
<ul>
<li>
<p>1）、JobManager 进程和 TaskManager 进程都由 Yarn NodeManager 监控；</p>
<p><a href="">		JobManager和TaskManager都是运行NodeManager容器Contanier中</a></p>
</li>
<li>
<p>2）、如果 JobManager 进程异常退出，则 Yarn ResourceManager 会重新调度 JobManager到其他机器；</p>
<ul>
<li><a href="">JobManager和AppMaster运行在同一个Container容器中</a></li>
</ul>
<p><img src="1629929588137.png" alt="" /></p>
<p><code>max-attempts</code>默认值：<code>2</code>，实际生产环境，可以调整大一点，比如：<code>4</code></p>
</li>
<li>
<p>3）、如果 TaskManager 进程异常退出，JobManager 会收到消息并重新向 Yarn ResourceManager 申请资源，重新启动 TaskManager；</p>
</li>
</ul>
<blockquote>
<p>Flink on YARN 运行机制示意图：<a href="">将JobManager和TaskManagers运行到YARN Container容器中。</a></p>
</blockquote>
<p><img src="1614763576727.png" alt="" /></p>
<ol>
<li>
<p>客户端Client上传<code>jar包和配置文件</code>到HDFS集群上；</p>
<ul>
<li>当启动一个Flink Yarn会话时，客户端首先会检查本次请求的资源是否足够；资源足够再上传。</li>
<li>YARN Client上传完成jar包和配置文件以后，再向RM提交任务；</li>
</ul>
</li>
<li>
<p><a href="">Client向YARN ResourceManager提交应用并申请资源；</a></p>
<ul>
<li>ResourceManager在NodeManager上启动容器，运行AppMaster，相当于JobManager进程。</li>
</ul>
</li>
<li>
<p><a href="">ResourceManager分配Container资源并启动ApplicationMaster，然后AppMaster加载Flink的Jar包和配置构建环境，启动JobManager；</a></p>
<ul>
<li>JobManager和ApplicationMaster运行在同一个Container上；</li>
<li>一旦JobManager被成功启动，AppMaster就知道JobManager的地址(AM它自己所在的机器)；</li>
<li>它就会为TaskManager生成一个新的Flink配置文件，此配置文件也被上传到HDFS上；</li>
<li>此外，AppMaster容器也提供了Flink的web服务接口；</li>
<li>YARN所分配的所有端口都是临时端口，这允许用户并行执行多个Flink</li>
</ul>
</li>
<li>
<p><a href="">ApplicationMaster向ResourceManager申请工作资源，NodeManager加载Flink的Jar包和配置<br />
构建环境并启动TaskManager（多个）。</a></p>
</li>
<li>
<p>TaskManager启动后向JobManager发送心跳包，并等待JobManager向其分配任务；</p>
</li>
</ol>
<p><img src="1633433408535.png" alt="1633433408535" /></p>
<h3 id="09-理解-flink-on-yarn之安装部署"><a class="markdownIt-Anchor" href="#09-理解-flink-on-yarn之安装部署"></a> 09-[理解]-Flink on YARN之安装部署</h3>
<hr />
<blockquote>
<p>Flink on YARN安装配置，此处考虑高可用HA配置，集群机器安装软件框架示意图：</p>
</blockquote>
<p><img src="1633437485506.png" alt="1633437485506" /></p>
<blockquote>
<ul>
<li>1）、关闭YARN的内存检查（<code>node1.itcast.cn</code>操作）</li>
</ul>
</blockquote>
<figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># yarn-site.xml中添加配置</span></span><br><span class="line">vim /export/server/hadoop/etc/hadoop/yarn-site.xml</span><br></pre></td></tr></table></figure>
<p>添加如下内容：</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- 关闭yarn内存检查 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.pmem-check-enabled<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>false<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.vmem-check-enabled<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>false<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span>	</span><br></pre></td></tr></table></figure>
<blockquote>
<ul>
<li>2）、 配置Application最大的尝试次数（<code>node1.itcast.cn</code>操作）</li>
</ul>
</blockquote>
<figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># yarn-site.xml中添加配置</span></span><br><span class="line">vim /export/server/hadoop/etc/hadoop/yarn-site.xml</span><br></pre></td></tr></table></figure>
<p>添加如下内容：</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.am.max-attempts<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">value</span>&gt;</span>4<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>
<blockquote>
<ul>
<li>3）、同步yarn-site.xml配置文件（<code>node1.itcast.cn</code>操作）</li>
</ul>
</blockquote>
<figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cd /export/server/hadoop/etc/hadoop</span><br><span class="line">scp -r yarn-site.xml root@node2.itcast.cn:$PWD</span><br><span class="line">scp -r yarn-site.xml root@node3.itcast.cn:$PWD</span><br></pre></td></tr></table></figure>
<blockquote>
<ul>
<li>4）、启动HDFS集群和YARN集群（<code>node1.itcast.cn</code>操作）</li>
</ul>
</blockquote>
<figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="section">[root@node1 ~]</span><span class="comment"># start-dfs.sh</span></span><br><span class="line"></span><br><span class="line"><span class="section">[root@node1 ~]</span><span class="comment"># start-yarn.sh</span></span><br></pre></td></tr></table></figure>
<blockquote>
<ul>
<li>5）、添加<code>HADOOP_CONF_DIR</code>环境变量(<strong>集群所有机器</strong>）</li>
</ul>
</blockquote>
<figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 添加环境变量</span></span><br><span class="line"> vim /etc/profile</span><br></pre></td></tr></table></figure>
<p>添加内容：</p>
<figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">export <span class="attr">HADOOP_CONF_DIR</span>=/export/server/hadoop/etc/hadoop</span><br></pre></td></tr></table></figure>
<p>环境变量生效</p>
<figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">source /etc/profile</span><br></pre></td></tr></table></figure>
<blockquote>
<ul>
<li>6）、上传软件及解压（<code>node1.itcast.cn</code>操作）</li>
</ul>
</blockquote>
<figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="section">[root@node1 ~]</span><span class="comment"># cd /export/software/</span></span><br><span class="line"><span class="section">[root@node1 software]</span><span class="comment"># rz</span></span><br><span class="line">	上传软件包：flink-1.13.1-bin-scala_2.11.tgz</span><br><span class="line">	</span><br><span class="line"><span class="section">[root@node1 software]</span><span class="comment"># chmod u+x flink-1.13.1-bin-scala_2.11.tgz</span></span><br><span class="line"><span class="section">[root@node1 software]</span><span class="comment"># tar -zxf flink-1.13.1-bin-scala_2.11.tgz -C /export/server/	</span></span><br><span class="line"></span><br><span class="line"><span class="section">[root@node1 ~]</span><span class="comment"># cd /export/server/</span></span><br><span class="line"><span class="section">[root@node1 server]</span><span class="comment"># chown -R root:root flink-1.13.1</span></span><br><span class="line"><span class="section">[root@node1 server]</span><span class="comment"># mv flink-1.13.1 flink-yarn</span></span><br></pre></td></tr></table></figure>
<blockquote>
<ul>
<li>7）、将Flink依赖Hadoop 框架JAR包上传至<code>/export/server/flink-yarn/lib</code>目录</li>
</ul>
</blockquote>
<p><img src="1633421482610.png" alt="1633421482610" /></p>
<figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="section">[root@node1 ~]</span><span class="comment"># cd /export/server/flink-yarn/lib/</span></span><br><span class="line"><span class="section">[root@node1 lib]</span><span class="comment"># rz</span></span><br><span class="line">	commons-cli-1.4.jar</span><br><span class="line">	flink-shaded-hadoop-3-uber-3.1.1.7.2.1.0-327-9.0.jar</span><br></pre></td></tr></table></figure>
<blockquote>
<ul>
<li>8）、配置HA高可用，依赖Zookeeper及重试次数（<code>node1.itcast.cn</code>操作）</li>
</ul>
</blockquote>
<figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 修改配置文件</span></span><br><span class="line">vim /export/server/flink-yarn/conf/flink-conf.yaml</span><br></pre></td></tr></table></figure>
<p>添加如下内容：</p>
<figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">high-availability: zookeeper</span><br><span class="line">high-availability.storageDir: hdfs://node1.itcast.cn:8020/flink/yarn-ha/</span><br><span class="line">high-availability.zookeeper.quorum: node1.itcast.cn:2181,node2.itcast.cn:2181,node3.itcast.cn:2181</span><br><span class="line">high-availability.zookeeper.path.root: /flink-yarn-ha</span><br><span class="line">high-availability.cluster-id: /cluster_yarn</span><br><span class="line"></span><br><span class="line">yarn.application-attempts: 10</span><br></pre></td></tr></table></figure>
<blockquote>
<ul>
<li>9）、集群所有机器，同步分发Flink 安装包，便于任意机器提交运行Flink Job。</li>
</ul>
</blockquote>
<figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">scp -r /export/server/flink-yarn root@node2.itcast.cn:/export/server/</span><br><span class="line"></span><br><span class="line">scp -r /export/server/flink-yarn root@node3.itcast.cn:/export/server/</span><br></pre></td></tr></table></figure>
<blockquote>
<ul>
<li>10）、启动Zookeeper集群（<code>node1.itcast.cn</code>操作）</li>
</ul>
</blockquote>
<figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">start-zk.sh</span><br></pre></td></tr></table></figure>
<p><img src="1652169020141.png" alt="1652169020141" /></p>
<blockquote>
<p>在Flink中执行应用有如下三种部署模式（Deployment  Mode）：</p>
</blockquote>
<p><img src="1633435043735.png" alt="1633435043735" /></p>
<h3 id="10-掌握-flink-on-yarn之session-模式运行"><a class="markdownIt-Anchor" href="#10-掌握-flink-on-yarn之session-模式运行"></a> 10-[掌握]-Flink on YARN之Session 模式运行</h3>
<hr />
<blockquote>
<p>Flink on YARN ：<code>Session 模式</code>，表示多个Flink Job运行共享Standalone集群资源。</p>
</blockquote>
<p>​	<a href="">先向Hadoop YARN申请资源，启动运行服务JobManager和TaskManagers，再提交多个Job到Flink 集群上执行。</a></p>
<p><img src="616953-20190705091842823-1472310397.png" alt="img" /></p>
<ul>
<li>无论JobManager还是TaskManager，都是运行NodeManager Contanier容器中，以JVM 进程方式运行；</li>
<li>提交每个Flink Job执行时，找的就是JobManager（<strong>AppMaster</strong>），找运行在YARN上应用ID；</li>
</ul>
<blockquote>
<p>​										<a href="">Session 会话模式：<code>yarn-session.sh</code>(开辟资源) + <code>flink run(</code>提交任务)</a></p>
</blockquote>
<ul>
<li>第一、Hadoop YARN 运行Flink 集群，开辟资源，使用：<code>yarn-session.sh</code>
<ul>
<li>在NodeManager上，启动容器Container运行<code>JobManager和TaskManagers</code></li>
</ul>
</li>
<li>第二、提交Flink Job执行，使用：<code>flink run</code></li>
</ul>
<blockquote>
<p>准备测试数据，测试运行批处理词频统计WordCount程序</p>
</blockquote>
<figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="section">[root@node1 ~]</span><span class="comment"># vim /root/words.txt</span></span><br></pre></td></tr></table></figure>
<p>添加数据</p>
<figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">spark python spark hive spark hive</span><br><span class="line">python spark hive spark python</span><br><span class="line">mapreduce spark hadoop hdfs hadoop spark</span><br><span class="line">hive mapreduce</span><br></pre></td></tr></table></figure>
<p>数据文件上传</p>
<figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="section">[root@node1 ~]</span><span class="comment"># hdfs dfs -mkdir -p /wordcount/input/</span></span><br><span class="line"><span class="section">[root@node1 ~]</span><span class="comment"># hdfs dfs -put /root/words.txt /wordcount/input/</span></span><br></pre></td></tr></table></figure>
<p><img src="1633422301964.png" alt="1633422301964" /></p>
<blockquote>
<ul>
<li>第一步、在yarn上启动一个Flink会话，<code>node1.itcast.cn</code>上执行以下命令</li>
</ul>
</blockquote>
<figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">export <span class="attr">HADOOP_CLASSPATH</span>=`hadoop classpath`</span><br><span class="line">/export/server/flink-yarn/bin/yarn-session.sh -d -jm 1024 -tm 1024 -s 2</span><br><span class="line"></span><br><span class="line"><span class="comment"># 参数说明</span></span><br><span class="line">-d：后台执行</span><br><span class="line">-s：	每个TaskManager的slot数量</span><br><span class="line">-jm：JobManager的内存（单位MB)</span><br><span class="line">-tm：每个TaskManager容器的内存（默认值：MB）</span><br><span class="line"></span><br><span class="line"><span class="comment"># 提交flink 集群运行yarn后，提示信息</span></span><br><span class="line">JobManager Web Interface: http://node1.itcast.cn:44263</span><br><span class="line">..................................................................</span><br><span class="line">$ echo &quot;stop&quot; | ./bin/yarn-session.sh -id application_1633441564219_0001</span><br><span class="line">If this should not be possible, then you can also kill Flink via YARN&#x27;s web interface or via:</span><br><span class="line">$ yarn application -kill application_1633441564219_0001</span><br></pre></td></tr></table></figure>
<blockquote>
<ul>
<li>第二步、查看UI界面，<a target="_blank" rel="noopener" href="http://node1.itcast.cn:8088/cluster/apps">http://node1.itcast.cn:8088/cluster/apps</a></li>
</ul>
</blockquote>
<p><img src="1633442327570.png" alt="1633442327570" /></p>
<blockquote>
<p>JobManager提供WEB UI：<a target="_blank" rel="noopener" href="http://node1.itcast.cn:8088/proxy/application_1614756061094_0002/#/overview">http://node1.itcast.cn:8088/proxy/application_1614756061094_0002/#/overview</a></p>
</blockquote>
<p><img src="1633442372444.png" alt="1633442372444" /></p>
<p><a href="">此时，没有任何TaskManager运行在容器Container中，需要等待有Flink Job提交执行时，才运行TaskManager。</a></p>
<blockquote>
<ul>
<li>第三步、使用<code>flink run</code>提交任务</li>
</ul>
</blockquote>
<figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">/export/server/flink-yarn/bin/flink run \</span><br><span class="line">-t yarn-session \</span><br><span class="line"><span class="attr">-Dyarn.application.id</span>=application_<span class="number">1652168669227_0001</span> \</span><br><span class="line">/export/server/flink-yarn/examples/batch/WordCount.jar \</span><br><span class="line">--input hdfs://node1.itcast.cn:8020/wordcount/input/words.txt</span><br></pre></td></tr></table></figure>
<p><img src="1633443314472.png" alt="1633443314472" /></p>
<blockquote>
<ul>
<li>第四步、通过上方的ApplicationMaster可以进入Flink的管理界面</li>
</ul>
</blockquote>
<p><img src="1633443391587.png" alt="1633443391587" /></p>
<blockquote>
<ul>
<li>第五步、关闭yarn-session</li>
</ul>
</blockquote>
<figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 优雅 停止应用，如果设置重启次数，即使停止应用，也会重启，一直到超过次数以后，才能真正停止应用</span></span><br><span class="line">echo &quot;stop&quot; | /export/server/flink-yarn/bin/yarn-session.sh -id application_1633441564219_0001</span><br><span class="line"></span><br><span class="line"><span class="comment"># kill 命令，直接将运行在yarn应用杀死，毫不留情</span></span><br><span class="line">yarn application -kill application_1633441564219_0001</span><br></pre></td></tr></table></figure>
<h3 id="11-掌握-flink-on-yarn之per-job-模式运行"><a class="markdownIt-Anchor" href="#11-掌握-flink-on-yarn之per-job-模式运行"></a> 11-[掌握]-Flink on YARN之Per-Job 模式运行</h3>
<hr />
<blockquote>
<p><a href="">每个Flink Job提交运行到Hadoop YARN集群时，根据自身的情况，单独向YARN申请资源，直到作业执行完成</a></p>
</blockquote>
<p><img src="616953-20190705091903367-1915964437.png" alt="img" /></p>
<p>​			在Hadoop YARN中，每次提交job都会创建一个新的Flink集群，任务之间相互独立，互不影响并且方便管理。任务执行完成之后创建的集群也会消失。</p>
<p>​				<a href="">采用Job分离模式，<strong>每个Flink Job运行，都会申请资源，运行属于自己的Flink 集群</strong>。</a></p>
<blockquote>
<ul>
<li>第一步、直接提交job</li>
</ul>
</blockquote>
<figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">export <span class="attr">HADOOP_CLASSPATH</span>=`hadoop classpath`</span><br><span class="line">/export/server/flink-yarn/bin/flink run \</span><br><span class="line">-t yarn-per-job -m yarn-cluster \</span><br><span class="line">-yjm 1024 -ytm 1024 -ys 1 \</span><br><span class="line">/export/server/flink-yarn/examples/batch/WordCount.jar \</span><br><span class="line">--input hdfs://node1.itcast.cn:8020/wordcount/input</span><br><span class="line"></span><br><span class="line"><span class="comment"># 参数说明</span></span><br><span class="line">-m：指定需要连接的jobmanager(主节点)地址，指定为 yarn-cluster，启动一个新的yarn-session</span><br><span class="line">-yjm：JobManager可用内存，单位兆</span><br><span class="line">-ytm：每个TM所在的Container可申请多少内存，单位兆</span><br><span class="line">-ys：每个TM会有多少个Slot</span><br><span class="line">-yd：分离模式（后台运行，不指定-yd, 终端会卡在提交的页面上）</span><br></pre></td></tr></table></figure>
<p><img src="1633444275790.png" alt="1633444275790" /></p>
<blockquote>
<ul>
<li>第二步、查看UI界面：<a target="_blank" rel="noopener" href="http://node1.itcast.cn:8088/cluster">http://node1.itcast.cn:8088/cluster</a></li>
</ul>
</blockquote>
<p><img src="1633444352887.png" alt="1633444352887" /></p>
<blockquote>
<p>提交Flink Job在Hadoop YARN执行时，最后给出如下错误警告：</p>
</blockquote>
<p><img src="1633444546416.png" alt="1633444546416" /></p>
<figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">解决办法： 在 flink 配置文件里 flink-conf.yaml设置</span><br><span class="line">	classloader.check-leaked-classloader: false</span><br></pre></td></tr></table></figure>
<h3 id="12-掌握-flink-on-yarn之application-模式运行"><a class="markdownIt-Anchor" href="#12-掌握-flink-on-yarn之application-模式运行"></a> 12-[掌握]-Flink on YARN之Application 模式运行</h3>
<hr />
<blockquote>
<p>​		<strong>Flink 1.11</strong> 引入了一种新的部署模式，即 <strong>Application</strong> 模式，目前可以支持基于 Hadoop YARN 和 Kubernetes 的 Application 模式。</p>
</blockquote>
<figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 1、Session 模式：</span></span><br><span class="line">	所有作业Job共享1个集群资源，隔离性差，JM 负载瓶颈，每个Job中main 方法在客户端执行。</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2、Per-Job 模式：</span></span><br><span class="line">	每个作业单独启动1个集群，隔离性好，JM 负载均衡，Job作业main 方法在客户端执行。</span><br></pre></td></tr></table></figure>
<p><img src="1633436605167.png" alt="1633436605167" /></p>
<p>​		以上两种模式，<mark>main方法都是在客户端执行</mark>，需要<strong>获取 flink 运行时所需的依赖项，并生成 JobGraph，提交到集群的操作都会在实时平台所在的机器上执行</strong>，那么将会给服务器造成很大的压力。此外，提交任务的时候会<strong>把本地flink的所有jar包先上传到hdfs上相应的临时目录</strong>，带来<mark>大量的网络的开销</mark>，所以如果任务特别多的情况下，平台的吞吐量将会直线下降。</p>
<blockquote>
<p>​		Application 模式下，<mark>用户程序的 main 方法将在<code>集群</code>中运行</mark>，用户<strong>将程序逻辑和依赖打包进一个可执行的 jar 包里</strong>，集群的入口程序 (ApplicationClusterEntryPoint) 负责调用其中的 main 方法来生成 JobGraph。</p>
</blockquote>
<p><img src="1633436948989.png" alt="1633436948989" /></p>
<p>​		<strong>Application 模式为每个提交的应用程序创建一个集群，并在应用程序完成时终止</strong>。Application 模式在不同应用之间提供了资源隔离和负载平衡保证。在特定一个应用程序上，JobManager 执行 m<strong>ain()</strong> 可以<a href="">节省所需的 CPU 周期</a>，还可以<a href="">节省本地下载依赖项所需的带宽</a>。</p>
<blockquote>
<p><mark>Application 模式</mark>使用 <code>bin/flink run-application</code> 提交作业，本质上是Session和Per-Job模式的折衷。</p>
</blockquote>
<ul>
<li>通过 <strong><code>-t</code></strong> 指定部署环境，目前支持部署在 yarn 上(<code>-t yarn-application</code>) 和 k8s 上(<code>-t kubernetes-application</code>）；</li>
<li>通过 <strong><code>-D</code></strong> 参数指定通用的运行配置，比如 jobmanager/taskmanager 内存、checkpoint 时间间隔等。</li>
</ul>
<figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">export <span class="attr">HADOOP_CLASSPATH</span>=`hadoop classpath`</span><br><span class="line"></span><br><span class="line">/export/server/flink-yarn/bin/flink run-application \</span><br><span class="line">-t yarn-application \</span><br><span class="line"><span class="attr">-Djobmanager.memory.process.size</span>=<span class="number">1024</span>m \</span><br><span class="line"><span class="attr">-Dtaskmanager.memory.process.size</span>=<span class="number">1024</span>m \</span><br><span class="line"><span class="attr">-Dtaskmanager.numberOfTaskSlots</span>=<span class="number">1</span> \</span><br><span class="line">/export/server/flink-yarn/examples/batch/WordCount.jar \</span><br><span class="line">--input hdfs://node1.itcast.cn:8020/wordcount/input</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>​		由于MAIN方法在JobManager（也就是NodeManager的容器Container）中执行，当Flink Job执行完成以后，启动<code>MRJobHistoryServer</code>历史服务器，查看AppMaster日志信息。</p>
<figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># node1.itcast.cn 上启动历史服务</span></span><br><span class="line"><span class="section">[root@node1 ~]</span><span class="comment"># mr-jobhistory-daemon.sh start historyserver </span></span><br></pre></td></tr></table></figure>
<p><img src="1633445478494.png" alt="1633445478494" /></p>
<blockquote>
<ul>
<li>第二步、查看UI界面：<a target="_blank" rel="noopener" href="http://node1.itcast.cn:8088/cluster">http://node1.itcast.cn:8088/cluster</a></li>
</ul>
</blockquote>
<p><img src="1633445508701.png" alt="1633445508701" /></p>
<blockquote>
<p>测试Flink Job不同运行模式时，注意事项如下：</p>
</blockquote>
<p><img src="1648681334840.png" alt="1648681334840" /></p>
<h2 id="第三部分flink-入门案例4个小节"><a class="markdownIt-Anchor" href="#第三部分flink-入门案例4个小节"></a> 第三部分：Flink 入门案例【4个小节】</h2>
<h3 id="13-掌握-flink-入门案例之编程模型"><a class="markdownIt-Anchor" href="#13-掌握-flink-入门案例之编程模型"></a> 13-[掌握]-Flink 入门案例之编程模型</h3>
<hr />
<p>​		基于Flink计算引擎，分别实现批处理（Batch）和流计算（Streaming ）中：<mark>词频统计WordCount</mark>。</p>
<blockquote>
<ul>
<li><mark>第一点：Flink API</mark> ，提供四个层次API，越在下面API，越复杂和灵活；越在上面API，使用越简单和抽象</li>
</ul>
</blockquote>
<p><img src="1614758479527.png" alt="" /></p>
<blockquote>
<ul>
<li><mark>第二点：编程模型</mark>，无论编写批处理还是流计算程序，分为三个部分：<mark>Source、Transformation和Sink</mark></li>
</ul>
</blockquote>
<p><img src="1614758699392.png" alt="" /></p>
<figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 第一步、从数据源DataSource获取数据</span></span><br><span class="line">	流计算：DataStream</span><br><span class="line">	批处理：DataSet</span><br><span class="line"></span><br><span class="line"><span class="comment"># 第二步、对数据进行转换处理</span></span><br><span class="line">	</span><br><span class="line"><span class="comment"># 第三步、结果数据输出DataSink</span></span><br></pre></td></tr></table></figure>
<blockquote>
<p>​			无论批处理Batch，还是流计算Stream，首先需要创建<code>执行环境ExecutionEnvironment对象</code>，类似Spark中<code>SparkSession</code>或者<code>SparkContext</code>。</p>
</blockquote>
<p><img src="1614758736610.png" alt="" /></p>
<blockquote>
<p>创建整个Flink基础课程Maven Project，设置MAVEN Repository仓库目录及Maven安装目录</p>
</blockquote>
<p><img src="1633445886187.png" alt="1633445886187" /></p>
<blockquote>
<p>​	<a href="">约定：每天创建一个Maven Module</a>，创建第1天Maven Module，模块结构：</p>
</blockquote>
<p><img src="1633446037078.png" alt="1633446037078" /></p>
<p>POM文件添加如下内容：</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">repositories</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">repository</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">id</span>&gt;</span>nexus-aliyun<span class="tag">&lt;/<span class="name">id</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>Nexus aliyun<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">url</span>&gt;</span>http://maven.aliyun.com/nexus/content/groups/public<span class="tag">&lt;/<span class="name">url</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">repository</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">repository</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">id</span>&gt;</span>central_maven<span class="tag">&lt;/<span class="name">id</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>central maven<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">url</span>&gt;</span>https://repo1.maven.org/maven2<span class="tag">&lt;/<span class="name">url</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">repository</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">repository</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">id</span>&gt;</span>cloudera<span class="tag">&lt;/<span class="name">id</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">url</span>&gt;</span>https://repository.cloudera.com/artifactory/cloudera-repos/<span class="tag">&lt;/<span class="name">url</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">repository</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">repository</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">id</span>&gt;</span>apache.snapshots<span class="tag">&lt;/<span class="name">id</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>Apache Development Snapshot Repository<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">url</span>&gt;</span>https://repository.apache.org/content/repositories/snapshots/<span class="tag">&lt;/<span class="name">url</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">releases</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">enabled</span>&gt;</span>false<span class="tag">&lt;/<span class="name">enabled</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">releases</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">snapshots</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">enabled</span>&gt;</span>true<span class="tag">&lt;/<span class="name">enabled</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">snapshots</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">repository</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">repositories</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">dependencies</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.flink<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>flink-java<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.13.1<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.flink<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>flink-streaming-java_2.11<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.13.1<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.flink<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>flink-clients_2.11<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.13.1<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.flink<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>flink-runtime-web_2.11<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.13.1<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.slf4j<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>slf4j-api<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.7.7<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">scope</span>&gt;</span>runtime<span class="tag">&lt;/<span class="name">scope</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.slf4j<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>slf4j-log4j12<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.7.7<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">scope</span>&gt;</span>runtime<span class="tag">&lt;/<span class="name">scope</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>log4j<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>log4j<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.2.17<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">scope</span>&gt;</span>runtime<span class="tag">&lt;/<span class="name">scope</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependencies</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">build</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">sourceDirectory</span>&gt;</span>src/main/java<span class="tag">&lt;/<span class="name">sourceDirectory</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">testSourceDirectory</span>&gt;</span>src/test/java<span class="tag">&lt;/<span class="name">testSourceDirectory</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">plugins</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!-- 编译插件 --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">plugin</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.maven.plugins<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>maven-compiler-plugin<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>3.5.1<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">source</span>&gt;</span>1.8<span class="tag">&lt;/<span class="name">source</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">target</span>&gt;</span>1.8<span class="tag">&lt;/<span class="name">target</span>&gt;</span></span><br><span class="line">                <span class="comment">&lt;!--&lt;encoding&gt;$&#123;project.build.sourceEncoding&#125;&lt;/encoding&gt;--&gt;</span></span><br><span class="line">            <span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">plugin</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">plugin</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.maven.plugins<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>maven-surefire-plugin<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.18.1<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">useFile</span>&gt;</span>false<span class="tag">&lt;/<span class="name">useFile</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">disableXmlReport</span>&gt;</span>true<span class="tag">&lt;/<span class="name">disableXmlReport</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">includes</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">include</span>&gt;</span>**/*Test.*<span class="tag">&lt;/<span class="name">include</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">include</span>&gt;</span>**/*Suite.*<span class="tag">&lt;/<span class="name">include</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;/<span class="name">includes</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">plugin</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!-- 打jar包插件(会包含所有依赖) --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">plugin</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.maven.plugins<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>maven-shade-plugin<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.3<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">executions</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">execution</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">phase</span>&gt;</span>package<span class="tag">&lt;/<span class="name">phase</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">goals</span>&gt;</span></span><br><span class="line">                        <span class="tag">&lt;<span class="name">goal</span>&gt;</span>shade<span class="tag">&lt;/<span class="name">goal</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;/<span class="name">goals</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">                        <span class="tag">&lt;<span class="name">filters</span>&gt;</span></span><br><span class="line">                            <span class="tag">&lt;<span class="name">filter</span>&gt;</span></span><br><span class="line">                                <span class="tag">&lt;<span class="name">artifact</span>&gt;</span>*:*<span class="tag">&lt;/<span class="name">artifact</span>&gt;</span></span><br><span class="line">                                <span class="tag">&lt;<span class="name">excludes</span>&gt;</span></span><br><span class="line">                                    <span class="comment">&lt;!--</span></span><br><span class="line"><span class="comment">                                    zip -d learn_spark.jar META-INF/*.RSA META-INF/*.DSA META-INF/*.SF --&gt;</span></span><br><span class="line">                                    <span class="tag">&lt;<span class="name">exclude</span>&gt;</span>META-INF/*.SF<span class="tag">&lt;/<span class="name">exclude</span>&gt;</span></span><br><span class="line">                                    <span class="tag">&lt;<span class="name">exclude</span>&gt;</span>META-INF/*.DSA<span class="tag">&lt;/<span class="name">exclude</span>&gt;</span></span><br><span class="line">                                    <span class="tag">&lt;<span class="name">exclude</span>&gt;</span>META-INF/*.RSA<span class="tag">&lt;/<span class="name">exclude</span>&gt;</span></span><br><span class="line">                                <span class="tag">&lt;/<span class="name">excludes</span>&gt;</span></span><br><span class="line">                            <span class="tag">&lt;/<span class="name">filter</span>&gt;</span></span><br><span class="line">                        <span class="tag">&lt;/<span class="name">filters</span>&gt;</span></span><br><span class="line">                        <span class="tag">&lt;<span class="name">transformers</span>&gt;</span></span><br><span class="line">                            <span class="tag">&lt;<span class="name">transformer</span> <span class="attr">implementation</span>=<span class="string">&quot;org.apache.maven.plugins.shade.resource.ManifestResourceTransformer&quot;</span>&gt;</span></span><br><span class="line">                                <span class="comment">&lt;!-- &lt;mainClass&gt;com.itcast.flink.WordCount&lt;/mainClass&gt; --&gt;</span></span><br><span class="line">                            <span class="tag">&lt;/<span class="name">transformer</span>&gt;</span></span><br><span class="line">                        <span class="tag">&lt;/<span class="name">transformers</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;/<span class="name">execution</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;/<span class="name">executions</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">plugin</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">plugins</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">build</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>日志配置文件：<code>log4j.properties</code></p>
<figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># This affects logging for both user code and Flink</span></span><br><span class="line"><span class="attr">log4j.rootLogger</span>=<span class="string">INFO, console</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment"># Uncomment this if you want to _only_ change Flink&#x27;s logging</span></span><br><span class="line"><span class="comment">#log4j.logger.org.apache.flink=INFO</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment"># The following lines keep the log level of common libraries/connectors on</span></span><br><span class="line"><span class="comment"># log level INFO. The root logger does not override this. You have to manually</span></span><br><span class="line"><span class="comment"># change the log levels here.</span></span><br><span class="line"><span class="attr">log4j.logger.akka</span>=<span class="string">INFO</span></span><br><span class="line"><span class="attr">log4j.logger.org.apache.kafka</span>=<span class="string">INFO</span></span><br><span class="line"><span class="attr">log4j.logger.org.apache.hadoop</span>=<span class="string">INFO</span></span><br><span class="line"><span class="attr">log4j.logger.org.apache.zookeeper</span>=<span class="string">INFO</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment"># Log all infos to the console</span></span><br><span class="line"><span class="attr">log4j.appender.console</span>=<span class="string">org.apache.log4j.ConsoleAppender</span></span><br><span class="line"><span class="attr">log4j.appender.console.layout</span>=<span class="string">org.apache.log4j.PatternLayout</span></span><br><span class="line"><span class="attr">log4j.appender.console.layout.ConversionPattern</span>=<span class="string">%d&#123;yyyy-MM-dd HH:mm:ss,SSS&#125; %-5p %-60c %x - %m%n</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment"># Suppress the irrelevant (wrong) warnings from the Netty channel handler</span></span><br><span class="line"><span class="attr">log4j.logger.org.apache.flink.shaded.akka.org.jboss.netty.channel.DefaultChannelPipeline</span>=<span class="string">ERROR, console</span></span><br></pre></td></tr></table></figure>
<blockquote>
<p>配置IDEA远程连接服务器，比如：<code>node1.itcast.cn</code></p>
</blockquote>
<p><img src="1629963813924.png" alt="" /></p>
<h3 id="14-掌握-flink-入门案例之wordcount批处理"><a class="markdownIt-Anchor" href="#14-掌握-flink-入门案例之wordcount批处理"></a> 14-[掌握]-Flink 入门案例之WordCount【批处理】</h3>
<hr />
<blockquote>
<p>首先，基于Flink计算引擎，<a href="">实现离线批处理Batch：从文本文件读取数据，词频统计</a>。</p>
</blockquote>
<p><img src="1633446519262.png" alt="1633446519262" /></p>
<blockquote>
<p>批处理时词频统计思路如下伪代码所示：</p>
</blockquote>
<figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">	spark flink flink flink spark</span><br><span class="line">				|</span><br><span class="line">				| flatMap</span><br><span class="line">				|</span><br><span class="line">3-1. 分割单词 spark, flink, flink, flink, spark</span><br><span class="line">					|</span><br><span class="line">                   | map</span><br><span class="line">                   |</span><br><span class="line">3-2. 转换二元组 (spark, 1) (flink, 1) (flink, 1) (flink, 1) (spark, 1)</span><br><span class="line">					|</span><br><span class="line">                   | groupBy(0)</span><br><span class="line">                   |</span><br><span class="line">3-3. 按照单词分组</span><br><span class="line">       spark -&gt; <span class="section">[(spark, 1) (spark, 1)]</span></span><br><span class="line">       flink -&gt; <span class="section">[(flink, 1) (flink, 1) (flink, 1) ]</span></span><br><span class="line">       			|</span><br><span class="line">                   |sum(1)</span><br><span class="line">                   |</span><br><span class="line">3-4. 组内数据求和，第二元素值累加</span><br><span class="line">       spark -&gt; 1 + <span class="attr">1</span> = <span class="number">2</span></span><br><span class="line">       flink -&gt; 1 + 1 + <span class="attr">1</span> =<span class="number">3</span></span><br></pre></td></tr></table></figure>
<blockquote>
<p>基于Flink编写批处理或流计算程序步骤如下：（5个步骤）</p>
</blockquote>
<figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">1.执行环境-env</span><br><span class="line">2.数据源-source</span><br><span class="line">3.数据转换-transformation</span><br><span class="line">4.数据接收器-sink</span><br><span class="line">5.触发执行-execute</span><br></pre></td></tr></table></figure>
<blockquote>
<p>编写批处理词频统计：<code>BatchWordCount</code>，创建Java类</p>
</blockquote>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> cn.itcast.flink.batch;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.common.functions.FlatMapFunction;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.common.functions.MapFunction;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.java.ExecutionEnvironment;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.java.operators.AggregateOperator;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.java.operators.DataSource;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.java.operators.FlatMapOperator;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.java.operators.MapOperator;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.java.tuple.Tuple2;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.util.Collector;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 使用Flink计算引擎实现离线批处理：词频统计WordCount</span></span><br><span class="line"><span class="comment">	 * 1.执行环境-env</span></span><br><span class="line"><span class="comment">	 * 2.数据源-source</span></span><br><span class="line"><span class="comment">	 * 3.数据转换-transformation</span></span><br><span class="line"><span class="comment">	 * 4.数据接收器-sink</span></span><br><span class="line"><span class="comment">	 * 5.触发执行-execute</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">BatchWordCount</span> &#123;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">		<span class="comment">// 1.执行环境-env</span></span><br><span class="line">		<span class="type">ExecutionEnvironment</span> <span class="variable">env</span> <span class="operator">=</span> ExecutionEnvironment.getExecutionEnvironment() ;</span><br><span class="line"></span><br><span class="line">		<span class="comment">// 2.数据源-source</span></span><br><span class="line">		DataSource&lt;String&gt; inputDataSet = env.readTextFile(<span class="string">&quot;datas/words.txt&quot;</span>);</span><br><span class="line"></span><br><span class="line">		<span class="comment">// 3.数据转换-transformation</span></span><br><span class="line">		<span class="comment">/*</span></span><br><span class="line"><span class="comment">			spark flink spark hbase spark</span></span><br><span class="line"><span class="comment">						|flatMap</span></span><br><span class="line"><span class="comment">			分割单词: spark, flink, spark</span></span><br><span class="line"><span class="comment">						|map</span></span><br><span class="line"><span class="comment">			转换二元组：(spark, 1)  (flink, 1) (spark, 1)， TODO：Flink Java API中提供元组类Tuple</span></span><br><span class="line"><span class="comment">						|groupBy(0)</span></span><br><span class="line"><span class="comment">			分组：spark -&gt; [(spark, 1), (spark, 1)]  flink -&gt; [(flink, 1)]</span></span><br><span class="line"><span class="comment">						|sum(1)</span></span><br><span class="line"><span class="comment">			求和：spark -&gt; 1 + 1 = 2,   flink = 1</span></span><br><span class="line"><span class="comment">		 */</span></span><br><span class="line">		<span class="comment">// 3-1. 分割单词</span></span><br><span class="line">		FlatMapOperator&lt;String, String&gt; wordDataSet = inputDataSet.flatMap(<span class="keyword">new</span> <span class="title class_">FlatMapFunction</span>&lt;String, String&gt;() &#123;</span><br><span class="line">			<span class="meta">@Override</span></span><br><span class="line">			<span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">flatMap</span><span class="params">(String line, Collector&lt;String&gt; out)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">				String[] words = line.trim().split(<span class="string">&quot;\\s+&quot;</span>);</span><br><span class="line">				<span class="keyword">for</span> (String word : words) &#123;</span><br><span class="line">					out.collect(word);</span><br><span class="line">				&#125;</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;);</span><br><span class="line"></span><br><span class="line">		<span class="comment">// 3-2. 转换二元组</span></span><br><span class="line">		MapOperator&lt;String, Tuple2&lt;String, Integer&gt;&gt; tupleDataSet = wordDataSet.map(<span class="keyword">new</span> <span class="title class_">MapFunction</span>&lt;String, Tuple2&lt;String, Integer&gt;&gt;() &#123;</span><br><span class="line">			<span class="meta">@Override</span></span><br><span class="line">			<span class="keyword">public</span> Tuple2&lt;String, Integer&gt; <span class="title function_">map</span><span class="params">(String word)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">				<span class="keyword">return</span> Tuple2.of(word, <span class="number">1</span>);</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;);</span><br><span class="line"></span><br><span class="line">		<span class="comment">// 3-3. 分组及求和, <span class="doctag">TODO:</span> 当数据类型为元组时，可以使用下标指定元素，从0开始</span></span><br><span class="line">		AggregateOperator&lt;Tuple2&lt;String, Integer&gt;&gt; resultDataSet = tupleDataSet.groupBy(<span class="number">0</span>).sum(<span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">		<span class="comment">// 4.数据接收器-sink</span></span><br><span class="line">		resultDataSet.print();</span><br><span class="line"></span><br><span class="line">		<span class="comment">// 5.触发执行-execute， TODO：批处理时，无需触发，流计算必须触发执行</span></span><br><span class="line">		<span class="comment">//env.execute(&quot;BatchWordCount&quot;) ;</span></span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h3 id="15-掌握-flink-入门案例之wordcount流计算"><a class="markdownIt-Anchor" href="#15-掌握-flink-入门案例之wordcount流计算"></a> 15-[掌握]-Flink 入门案例之WordCount【流计算】</h3>
<hr />
<blockquote>
<p>编写Flink程序，<strong>接收TCP Socket的单词数据，并以空格进行单词拆分，分组统计单词个数</strong>。</p>
</blockquote>
<p><img src="1633446557864.png" alt="1633446557864" /></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> cn.itcast.flink.stream;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.common.functions.FlatMapFunction;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.common.functions.MapFunction;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.java.tuple.Tuple2;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.datastream.DataStreamSource;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.datastream.SingleOutputStreamOperator;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.util.Collector;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 使用Flink计算引擎实现实时流计算：词频统计WordCount，从TCP Socket消费数据，结果打印控制台。</span></span><br><span class="line"><span class="comment">	 * 1.执行环境-env</span></span><br><span class="line"><span class="comment">	 * 2.数据源-source</span></span><br><span class="line"><span class="comment">	 * 3.数据转换-transformation</span></span><br><span class="line"><span class="comment">	 * 4.数据接收器-sink</span></span><br><span class="line"><span class="comment">	 * 5.触发执行-execute</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">StreamWordCount</span> &#123;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">		<span class="comment">// 1.执行环境-env</span></span><br><span class="line">		<span class="type">StreamExecutionEnvironment</span> <span class="variable">env</span> <span class="operator">=</span> StreamExecutionEnvironment.getExecutionEnvironment();</span><br><span class="line"></span><br><span class="line">		<span class="comment">// 2.数据源-source</span></span><br><span class="line">		DataStreamSource&lt;String&gt; inputDataStream = env.socketTextStream(<span class="string">&quot;node1.itcast.cn&quot;</span>, <span class="number">9999</span>);</span><br><span class="line"></span><br><span class="line">		<span class="comment">// 3.数据转换-transformation</span></span><br><span class="line">		SingleOutputStreamOperator&lt;Tuple2&lt;String, Integer&gt;&gt; resultDataStream = inputDataStream</span><br><span class="line">			<span class="comment">// 3-1. 分割单词</span></span><br><span class="line">			.flatMap(<span class="keyword">new</span> <span class="title class_">FlatMapFunction</span>&lt;String, String&gt;() &#123;</span><br><span class="line">				<span class="meta">@Override</span></span><br><span class="line">				<span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">flatMap</span><span class="params">(String line, Collector&lt;String&gt; out)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">					<span class="keyword">for</span> (String word : line.trim().split(<span class="string">&quot;\\s+&quot;</span>)) &#123;</span><br><span class="line">						out.collect(word);</span><br><span class="line">					&#125;</span><br><span class="line">				&#125;</span><br><span class="line">			&#125;)</span><br><span class="line">			<span class="comment">// 3-2. 转换二元组</span></span><br><span class="line">			.map(<span class="keyword">new</span> <span class="title class_">MapFunction</span>&lt;String, Tuple2&lt;String, Integer&gt;&gt;() &#123;</span><br><span class="line">				<span class="meta">@Override</span></span><br><span class="line">				<span class="keyword">public</span> Tuple2&lt;String, Integer&gt; <span class="title function_">map</span><span class="params">(String word)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">					<span class="keyword">return</span> <span class="keyword">new</span> <span class="title class_">Tuple2</span>&lt;&gt;(word, <span class="number">1</span>);</span><br><span class="line">				&#125;</span><br><span class="line">			&#125;)</span><br><span class="line">			<span class="comment">// 3-3. 分组和组内求和</span></span><br><span class="line">			.keyBy(<span class="number">0</span>).sum(<span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">		<span class="comment">// 4.数据接收器-sink</span></span><br><span class="line">		resultDataStream.print();</span><br><span class="line"></span><br><span class="line">		<span class="comment">// 5.触发执行-execute</span></span><br><span class="line">		env.execute(<span class="string">&quot;StreamWordCount&quot;</span>);</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<blockquote>
<p>​			Apache Flink <code>1.12.0</code> 正式发布，<code>流批一体</code>真正统一运行！<a href="">在 DataStream API 上添加了高效的批执行模式的支持。</a>批处理和流处理实现真正统一的运行时的一个重要里程碑。</p>
</blockquote>
<p><img src="1614734865437.png" alt="" /></p>
<blockquote>
<p>​		在 Flink 1.12 中，默认执行模式为 <code>STREAMING</code>，要将作业配置为以 <code>BATCH</code> 模式运行，可以在提交作业的时候，设置参数 <code>execution.runtime-mode</code>。</p>
<p>文档：<a target="_blank" rel="noopener" href="https://nightlies.apache.org/flink/flink-docs-release-1.13/docs/dev/datastream/execution_mode/">https://nightlies.apache.org/flink/flink-docs-release-1.13/docs/dev/datastream/execution_mode/</a></p>
</blockquote>
<p><img src="1633447728418.png" alt="1633447728418" /></p>
<blockquote>
<p>修改流计算词频统计，从本地系统文本文件加载数据，处理数据，设置执行模式为：<code>Batch</code>。</p>
</blockquote>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> cn.itcast.flink.execution;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.common.RuntimeExecutionMode;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.common.functions.FlatMapFunction;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.common.functions.MapFunction;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.java.tuple.Tuple2;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.datastream.DataStreamSource;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.datastream.SingleOutputStreamOperator;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.util.Collector;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 使用Flink计算引擎实现离线批处理：词频统计WordCount，TODO：从Flink 1.12开始，流批一体化，API统一，设置执行模式即可</span></span><br><span class="line"><span class="comment">	 * 1.执行环境-env</span></span><br><span class="line"><span class="comment">	 * 2.数据源-source</span></span><br><span class="line"><span class="comment">	 * 3.数据转换-transformation</span></span><br><span class="line"><span class="comment">	 * 4.数据接收器-sink</span></span><br><span class="line"><span class="comment">	 * 5.触发执行-execute</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">ExecutionWordCount</span> &#123;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">		<span class="comment">// 1.执行环境-env</span></span><br><span class="line">		<span class="type">StreamExecutionEnvironment</span> <span class="variable">env</span> <span class="operator">=</span> StreamExecutionEnvironment.getExecutionEnvironment();</span><br><span class="line">		<span class="comment">// <span class="doctag">TODO:</span> 设置执行模式execute-mode为Batch批处理</span></span><br><span class="line">		env.setRuntimeMode(RuntimeExecutionMode.BATCH) ;</span><br><span class="line"></span><br><span class="line">		<span class="comment">// 2.数据源-source</span></span><br><span class="line">		DataStreamSource&lt;String&gt; inputDataStream = env.readTextFile(<span class="string">&quot;datas/words.txt&quot;</span>) ;</span><br><span class="line"></span><br><span class="line">		<span class="comment">// 3.数据转换-transformation</span></span><br><span class="line">		SingleOutputStreamOperator&lt;Tuple2&lt;String, Integer&gt;&gt; resultDataStream = inputDataStream</span><br><span class="line">			<span class="comment">// 3-1. 分割单词</span></span><br><span class="line">			.flatMap(<span class="keyword">new</span> <span class="title class_">FlatMapFunction</span>&lt;String, String&gt;() &#123;</span><br><span class="line">				<span class="meta">@Override</span></span><br><span class="line">				<span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">flatMap</span><span class="params">(String line, Collector&lt;String&gt; out)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">					<span class="keyword">for</span> (String word : line.trim().split(<span class="string">&quot;\\s+&quot;</span>)) &#123;</span><br><span class="line">						out.collect(word);</span><br><span class="line">					&#125;</span><br><span class="line">				&#125;</span><br><span class="line">			&#125;)</span><br><span class="line">			<span class="comment">// 3-2. 转换二元组</span></span><br><span class="line">			.map(<span class="keyword">new</span> <span class="title class_">MapFunction</span>&lt;String, Tuple2&lt;String, Integer&gt;&gt;() &#123;</span><br><span class="line">				<span class="meta">@Override</span></span><br><span class="line">				<span class="keyword">public</span> Tuple2&lt;String, Integer&gt; <span class="title function_">map</span><span class="params">(String word)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">					<span class="keyword">return</span> <span class="keyword">new</span> <span class="title class_">Tuple2</span>&lt;&gt;(word, <span class="number">1</span>);</span><br><span class="line">				&#125;</span><br><span class="line">			&#125;)</span><br><span class="line">			<span class="comment">// 3-3. 分组和组内求和</span></span><br><span class="line">			.keyBy(<span class="number">0</span>).sum(<span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">		<span class="comment">// 4.数据接收器-sink</span></span><br><span class="line">		resultDataStream.print();</span><br><span class="line"></span><br><span class="line">		<span class="comment">// 5.触发执行-execute</span></span><br><span class="line">		env.execute(<span class="string">&quot;StreamWordCount&quot;</span>);</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<blockquote>
<p>前面提交运行Flink Job时，通过 <code>--input、--output、--host</code>和 <code>--port</code> 传递参数，如下命令：</p>
</blockquote>
<figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">/export/server/flink-local/bin/flink run \</span><br><span class="line">/export/server/flink-local/examples/batch/WordCount.jar \</span><br><span class="line">--input /root/words.txt --output /root/output</span><br></pre></td></tr></table></figure>
<blockquote>
<p>​		修改流式程序，从应用程序传递参数：<code>host和port</code>，使用Flink中工具类：<code>ParameterTool</code>，解析参数，代码如下所示：</p>
</blockquote>
<p>文档：<a target="_blank" rel="noopener" href="https://ci.apache.org/projects/flink/flink-docs-release-1.13/docs/dev/datastream/application_parameters/">https://ci.apache.org/projects/flink/flink-docs-release-1.13/docs/dev/datastream/application_parameters/</a></p>
<p><img src="1630745360506.png" alt="" /></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> cn.itcast.flink;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.common.functions.FlatMapFunction;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.common.functions.MapFunction;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.java.tuple.Tuple2;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.java.utils.ParameterTool;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.datastream.DataStreamSource;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.datastream.SingleOutputStreamOperator;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.util.Collector;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 使用Flink计算引擎实现实时流计算：词频统计WordCount，从TCP Socket消费数据，结果打印控制台。</span></span><br><span class="line"><span class="comment">	 * 1.执行环境-env</span></span><br><span class="line"><span class="comment">	 * 2.数据源-source</span></span><br><span class="line"><span class="comment">	 * 3.数据转换-transformation</span></span><br><span class="line"><span class="comment">	 * 4.数据接收器-sink</span></span><br><span class="line"><span class="comment">	 * 5.触发执行-execute</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">WordCount</span> &#123;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line"></span><br><span class="line">		<span class="comment">// <span class="doctag">TODO:</span> 构建参数解析工具类实例对象</span></span><br><span class="line">		<span class="type">ParameterTool</span> <span class="variable">parameterTool</span> <span class="operator">=</span> ParameterTool.fromArgs(args);</span><br><span class="line">		<span class="keyword">if</span>(parameterTool.getNumberOfParameters() != <span class="number">2</span>)&#123;</span><br><span class="line">			System.out.println(<span class="string">&quot;Usage: WordCount --host &lt;hostname&gt; --port &lt;port&gt; .........&quot;</span>);</span><br><span class="line">			System.exit(-<span class="number">1</span>);</span><br><span class="line">		&#125;</span><br><span class="line">		<span class="keyword">final</span> <span class="type">String</span> <span class="variable">host</span> <span class="operator">=</span> parameterTool.get(<span class="string">&quot;host&quot;</span>) ; <span class="comment">// 直接传递参数，获取值</span></span><br><span class="line">		<span class="keyword">final</span> <span class="type">int</span> <span class="variable">port</span> <span class="operator">=</span> parameterTool.getInt(<span class="string">&quot;port&quot;</span>, <span class="number">9999</span>) ; <span class="comment">// 如果没有参数，使用默认值</span></span><br><span class="line"></span><br><span class="line">		<span class="comment">// 1.执行环境-env</span></span><br><span class="line">		<span class="type">StreamExecutionEnvironment</span> <span class="variable">env</span> <span class="operator">=</span> StreamExecutionEnvironment.getExecutionEnvironment();</span><br><span class="line">		env.setParallelism(<span class="number">2</span>) ; <span class="comment">// 设置并行度</span></span><br><span class="line"></span><br><span class="line">		<span class="comment">// 2.数据源-source</span></span><br><span class="line">		DataStreamSource&lt;String&gt; inputDataStream = env.socketTextStream(host, port);</span><br><span class="line"></span><br><span class="line">		<span class="comment">// 3.数据转换-transformation</span></span><br><span class="line">		SingleOutputStreamOperator&lt;Tuple2&lt;String, Integer&gt;&gt; resultDataStream = inputDataStream</span><br><span class="line">			<span class="comment">// 3-1. 分割单词</span></span><br><span class="line">			.flatMap(<span class="keyword">new</span> <span class="title class_">FlatMapFunction</span>&lt;String, String&gt;() &#123;</span><br><span class="line">				<span class="meta">@Override</span></span><br><span class="line">				<span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">flatMap</span><span class="params">(String line, Collector&lt;String&gt; out)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">					<span class="keyword">for</span> (String word : line.trim().split(<span class="string">&quot;\\s+&quot;</span>)) &#123;</span><br><span class="line">						out.collect(word);</span><br><span class="line">					&#125;</span><br><span class="line">				&#125;</span><br><span class="line">			&#125;)</span><br><span class="line">			<span class="comment">// 3-2. 转换二元组</span></span><br><span class="line">			.map(<span class="keyword">new</span> <span class="title class_">MapFunction</span>&lt;String, Tuple2&lt;String, Integer&gt;&gt;() &#123;</span><br><span class="line">				<span class="meta">@Override</span></span><br><span class="line">				<span class="keyword">public</span> Tuple2&lt;String, Integer&gt; <span class="title function_">map</span><span class="params">(String word)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">					<span class="keyword">return</span> <span class="keyword">new</span> <span class="title class_">Tuple2</span>&lt;&gt;(word, <span class="number">1</span>);</span><br><span class="line">				&#125;</span><br><span class="line">			&#125;)</span><br><span class="line">			<span class="comment">// 3-3. 分组和组内求和</span></span><br><span class="line">			.keyBy(<span class="number">0</span>).sum(<span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">		<span class="comment">// 4.数据接收器-sink</span></span><br><span class="line">		resultDataStream.print();</span><br><span class="line"></span><br><span class="line">		<span class="comment">// 5.触发执行-execute</span></span><br><span class="line">		env.execute(<span class="string">&quot;StreamWordCount&quot;</span>);</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h3 id="16-掌握-flink-入门案例之打包部署运行"><a class="markdownIt-Anchor" href="#16-掌握-flink-入门案例之打包部署运行"></a> 16-[掌握]-Flink 入门案例之打包部署运行</h3>
<hr />
<blockquote>
<p>Flink 程序提交运行方式有两种：</p>
</blockquote>
<ul>
<li>1）、方式一：以命令行的方式提交：<code>flink run</code></li>
<li>2）、方式二：以UI界面方式提交</li>
</ul>
<blockquote>
<p>​		命令行方式提交Flink应用，可以运行至<strong>Standalone集群和YARN集群</strong>，以运行<strong>YARN Job分离模式</strong>为例演示提交Flink应用程序。</p>
</blockquote>
<ul>
<li>1）、应用程序编译打包：<code>flink-day01-1.0.0.jar</code>，不包含其他依赖jar包，删除log4j配置文件。</li>
</ul>
<p><img src="1652322463648.png" alt="1652322463648" /></p>
<ul>
<li>2）、启动HDFS集群和YARN集群</li>
</ul>
<figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 在node1.itcast.cn上启动服务</span></span><br><span class="line">start-zk.sh</span><br><span class="line"></span><br><span class="line">start-dfs.sh</span><br><span class="line"></span><br><span class="line">start-yarn.sh</span><br></pre></td></tr></table></figure>
<ul>
<li>3）、上传作业jar包到linux服务器</li>
</ul>
<figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd /export/server/flink-yarn/</span><br><span class="line">rz</span><br></pre></td></tr></table></figure>
<ul>
<li>4）、提交运行</li>
</ul>
<figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">/export/server/flink-yarn/bin/flink run \</span><br><span class="line">-t yarn-per-job \</span><br><span class="line">-m yarn-cluster \</span><br><span class="line">-yjm 1024 -ytm 1024 -ys 1 \</span><br><span class="line">--class cn.itcast.flink.WordCount \</span><br><span class="line">/export/server/flink-yarn/flink-day01-1.0.0.jar \</span><br><span class="line">--host node1.itcast.cn --port 9999</span><br></pre></td></tr></table></figure>
<ul>
<li>5）、第三步、查看任务运行概述</li>
</ul>
<p><img src="1633448743408.png" alt="1633448743408" /></p>
<blockquote>
<p>​			UI 方式提交，此种方式提交应用，可以提交Flink Job在<code>Flink Standalone集群和YARN Session会话模式</code>下，此处<strong>以YARN Session为例</strong>演示。</p>
</blockquote>
<ul>
<li>1）、第一步、启动HDFS集群和YARN集群</li>
</ul>
<figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 在node1.itcast.cn上启动服务</span></span><br><span class="line">start-zk.sh</span><br><span class="line"></span><br><span class="line">start-dfs.sh</span><br><span class="line"></span><br><span class="line">start-yarn.sh</span><br></pre></td></tr></table></figure>
<ul>
<li>2）、第二步、启动YARN Session</li>
</ul>
<figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">export <span class="attr">HADOOP_CLASSPATH</span>=`hadoop classpath`</span><br><span class="line">/export/server/flink-yarn/bin/yarn-session.sh -d -jm 1024 -tm 1024 -s 1</span><br></pre></td></tr></table></figure>
<ul>
<li>3）、第三步、上传作业jar包及指定相关参数</li>
</ul>
<p><img src="1633448931513.png" alt="1633448931513" /></p>
<p>选择打成jar包，然后填写参数值，截图如下：</p>
<p><img src="1633449004149.png" alt="1633449004149" /></p>
<p>参数内容：</p>
<figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Entry Class：cn.itcast.flink.WordCount</span><br><span class="line">Program Arguments：--host node1.itcast.cn --port 9999</span><br></pre></td></tr></table></figure>
<p>点击显示计划【Show Plan】:</p>
<p><img src="1633449021605.png" alt="1633449021605" /></p>
<p>点击提交按钮【Submit】，运行Flink应用。</p>
<ul>
<li>4）、第四步、查看任务运行概述</li>
</ul>
<p><img src="1633449120710.png" alt="1633449120710" /></p>
<h2 id="附录部分注意事项及扩展内容"><a class="markdownIt-Anchor" href="#附录部分注意事项及扩展内容"></a> 附录部分：注意事项及扩展内容</h2>
<h3 id="附录1-流计算引擎的演进"><a class="markdownIt-Anchor" href="#附录1-流计算引擎的演进"></a> [附录1]-流计算引擎的演进</h3>
<hr />
<blockquote>
<p>至今为止，大数据技术栈中，针对流式数据处理，主要有如下三代流式计算引擎：</p>
</blockquote>
<p><img src="1633396038901.png" alt="1633396038901" /></p>
<hr />
<ul>
<li>
<p>第一代：<code>Apache Storm</code>（Alibaba <code>JStorm</code>）</p>
<p><a href="">流计算引擎进行了很多代的演进，第一代流计算引擎 Apache Storm 是一个纯流的设计，延迟非常的低，但是它的问题也比较明显，即没有办法避免消息的重复处理，从而导致数据正确性有一定的问题。</a></p>
<p><code>https://storm.apache.org/</code></p>
</li>
</ul>
<p><img src="1629902040441.png" alt="" /></p>
<hr />
<ul>
<li>
<p>第二代：<code>Spark Streaming</code>，DStream = Seq[RDD]</p>
<p><a href="">Spark Streaming 是第二代流计算引擎，解决了流计算语义正确性的问题，但是它的设计理念是以批为核心，最大的问题是延迟比较高，只能做到 10 秒级别的延迟，端到端无法实现秒以内的延迟。</a></p>
<p><code>https://spark.apache.org/streaming/</code></p>
</li>
</ul>
<p><img src="1629902078825.png" alt="" /></p>
<hr />
<ul>
<li>
<p>第三代：<code>Apache Flink</code>（Alibaba <code>Blink</code>）</p>
<p><a href="">Flink 是第三代流计算引擎，也是最新一代的流计算引擎。它既可以保证低延迟，同时又可以保证消息的一致性语义，对于内置状态的管理，也极大降低了应用程序的复杂度。</a></p>
<p><code>https://flink.apache.org/</code></p>
</li>
</ul>
<p><img src="1629902139034.png" alt="" /></p>
<blockquote>
<p>Google 发布流式处理系统论文：<code>Google DataFlow</code>，定义流式计算引擎该有哪些功能。</p>
</blockquote>
<p><img src="1630749492194.png" alt="" /></p>
<h3 id="附录2-flink-框架技术栈"><a class="markdownIt-Anchor" href="#附录2-flink-框架技术栈"></a> [附录2]-Flink 框架技术栈</h3>
<hr />
<blockquote>
<p>一个计算框架要有长远的发展，必须打造一个完整的<code>生态栈Stack</code>（生态圈）。</p>
</blockquote>
<p><img src="4092059-b6ff29d09ba6da97.png" alt="img" /></p>
<blockquote>
<ul>
<li>
<p>1）、<strong>物理部署层</strong>：Flink 支持本地运行、能在独立集群或者在被 YARN 管理的集群上运行， 也能<br />
部署在云上；</p>
<p><a href="">类似MapReduce程序和Spark 应用程序运行部署地方，要么本地Local，要么集群，要么云服务。</a></p>
</li>
<li>
<p>2）、<strong>Runtime核心层</strong>：提供了支持Flink计算的全部核心实现；</p>
</li>
<li>
<p>3）、<strong>API&amp;Libraries层</strong>：DataStream、DataSet、Table、SQL API，在学习API中中，主要还是使用DataStreamAPI 和Table API &amp; SQL；</p>
<p><a href="">类似<code>SparkCore：RDD API</code>和<code>SparkSQL：DataFrame SQL及DSL</code></a></p>
<p><mark>从Flink 1.12版本开始，流批一体化，使用DataStream API进行流计算和批处理，并且Flink Table API和SQL稳定，官方建议使用处理数据。</mark></p>
</li>
<li>
<p>4）、<strong>扩展库</strong>：<code>复杂事件处理CEP</code>、机器学习库FlinkML、图处理库Gelly；</p>
</li>
</ul>
</blockquote>
<h3 id="附录3-flink-扩展性阅读"><a class="markdownIt-Anchor" href="#附录3-flink-扩展性阅读"></a> [附录3]-Flink 扩展性阅读</h3>
<hr />
<p>​		此外，提供Flink 框架“八卦”新闻，大家可以自己阅读，更加了解Flink框架。</p>
<blockquote>
<ul>
<li>1）、Flink 发展现状，目前来说，Flink在中国发展相当迅速，尤其是阿里在进行推动。</li>
</ul>
</blockquote>
<p><a href="">全球Flink热度情况：</a></p>
<p><img src="1614738294044.png" alt="" /></p>
<p><a href="">Apache Flink使用用户：</a></p>
<p><img src="1614738308219.png" alt="" /></p>
<p><a href="">Flink 在阿里使用情况（2020.6）：</a></p>
<p><img src="1614738339577.png" alt="" /></p>
<blockquote>
<ul>
<li>2）、为什么选择 Flink</li>
</ul>
</blockquote>
<p><img src="1614738387322.png" alt="" /></p>
<blockquote>
<ul>
<li>3）、大数据分析引擎发展史，在国外一些社区，有很多人将大数据的计算引擎分成了 4 代。</li>
</ul>
</blockquote>
<p><img src="1633399667903.png" alt="1633399667903" /></p>
<blockquote>
<ul>
<li>4）、流式计算和批量计算</li>
</ul>
</blockquote>
<p><img src="1614738443208.png" alt="" /></p>
<figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">Flink 技术框架学习：</span><br><span class="line">1、Flink 中文学习网站</span><br><span class="line">	一手资料，都是大厂分析资料</span><br><span class="line">	https://flink-learning.org.cn/</span><br><span class="line">	</span><br><span class="line">2、Flink 官方文档</span><br><span class="line">	使用什么版本Flink，就看什么文档</span><br><span class="line">	https://ci.apache.org/projects/flink/flink-docs-release-1.10/</span><br></pre></td></tr></table></figure>
<h3 id="附录4-flink-standalone-集群回顾"><a class="markdownIt-Anchor" href="#附录4-flink-standalone-集群回顾"></a> [附录4]-Flink Standalone 集群回顾</h3>
<hr />
<blockquote>
<p>Flink Standalone集群安装部署，总结回顾说明如下：</p>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">1、Flink 集群架构</span><br><span class="line">	1）、JobManager 老大</span><br><span class="line">		Master</span><br><span class="line">		接收提交Job，调度Job执行</span><br><span class="line">	2）、TaskManager 小弟</span><br><span class="line">		Slavers</span><br><span class="line">		运行Task任务</span><br><span class="line">		</span><br><span class="line">	Flink Client</span><br><span class="line">		提交Flink Job运行，提交给JobManager</span><br></pre></td></tr></table></figure>
<p><img src="1630737225965.png" alt="" /></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">2、本地集群部署</span><br><span class="line">	将JobManager和TaskManager运行1台机器上，分别启动JM和TM进程（JVM进程）</span><br><span class="line">	测试：流计算程序、批处理程序，使用flink run 提交运行Job</span><br></pre></td></tr></table></figure>
<p><img src="1630737282282.png" alt="" /></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">3、分布式集群（Standalone集群）</span><br><span class="line">	多台机器部署，1个JobManager和多个TaskManager，需要进行基础配置</span><br></pre></td></tr></table></figure>
<p><img src="1630737374891.png" alt="" /></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">4、HA高可用集群</span><br><span class="line">	多台机器部署，多个JobManager和多个TaskManager，其中1个JobManager为Active，其他为Standby</span><br><span class="line">	依赖Zookeeper集群，实现leader选举功能和监控转移转移。</span><br></pre></td></tr></table></figure>
<p><img src="1630737480781.png" alt="" /></p>
<h3 id="附录5-hadoop-yarn-回顾复习"><a class="markdownIt-Anchor" href="#附录5-hadoop-yarn-回顾复习"></a> [附录5]-Hadoop YARN 回顾复习</h3>
<hr />
<blockquote>
<p>​		Hadoop YARN在国内使用比较广泛，基本上大多数公司在生产环境中都使用Hadoop  YARN 管理集群资源，Hadoop YARN 集群中的组件包括：</p>
</blockquote>
<p><img src="1633429200420.png" alt="1633429200420" /></p>
<blockquote>
<p><a href="">YARN中最重要的角色是 <code>ResourceManager</code>，主要用来负责整个资源的管理，Client 端是负责向 RM提交任务。</a></p>
</blockquote>
<p><img src="42f2a89111db24fb3a28792ca3890b4a.png" alt="img" /></p>
<ol>
<li>用户在 Client 端提交任务后会先给到 Resource Manager；</li>
<li>Resource Manager 会启动 Container，接着进一步启动 Application Master，即对 Master 节点的启动。</li>
<li>当 Master 节点启动之后，会向 Resource Manager 再重新申请资源，当 Resource Manager 将资源分配给 Application Master 之后，Application Master 再将具体的 Task 调度起来去执行。</li>
</ol>
<h3 id="附录6-flink-on-yarn-三种部署模式"><a class="markdownIt-Anchor" href="#附录6-flink-on-yarn-三种部署模式"></a> [附录6]-Flink on YARN 三种部署模式</h3>
<hr />
<blockquote>
<p>Flink 执行应用三种部署模式区别：</p>
</blockquote>
<p><img src="deployment_modes.svg" alt="Figure for Deployment Modes" /></p>
<blockquote>
<ul>
<li>1）、<strong>Session Mode（会话共享模式）</strong></li>
</ul>
</blockquote>
<p><img src="1633436033528.png" alt="1633436033528" /></p>
<ul>
<li>特点：需要先申请资源，使用Flink中的<code>yarn-session</code>（yarn客户端），启动JobManager和TaskManger</li>
<li>优点：不需要每次递交作业申请资源，而是使用已经申请好的资源，从而提高执行效率</li>
<li>缺点：作业执行完成以后，资源不会被释放，因此一直会占用系统资源</li>
<li>应用场景：适合作业递交比较频繁的场景，小作业比较多的场景</li>
</ul>
<blockquote>
<ul>
<li><strong>2）、Pre-Job Mode（Job 分离模式）</strong></li>
</ul>
</blockquote>
<p><img src="1633436301371.png" alt="1633436301371" /></p>
<ul>
<li>特点：每次递交作业都需要申请一次资源</li>
<li>优点：作业运行完成，资源会立刻被释放，不会一直占用系统资源</li>
<li>缺点：每次递交作业都需要申请资源，会影响执行效率，因为申请资源需要消耗时间</li>
<li>应用场景：适合作业比较少的场景、大作业的场景</li>
</ul>
<blockquote>
<ul>
<li><strong>3）、Application Mode（应用模式）</strong></li>
</ul>
</blockquote>
<p>​		<strong>Flink 1.11</strong> 引入了一种新的部署模式，即 <strong>Application</strong> 模式。目前可以支持基于 Hadoop YARN 和 Kubernetes 的 Application 模式。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">1、Session 模式：</span><br><span class="line">	所有作业共享集群资源，隔离性差，JM 负载瓶颈，main 方法在客户端执行。</span><br><span class="line"></span><br><span class="line">2、Per-Job 模式：</span><br><span class="line">	每个作业单独启动集群，隔离性好，JM 负载均衡，main 方法在客户端执行。</span><br></pre></td></tr></table></figure>
<p><img src="1633436605167.png" alt="1633436605167" /></p>
<p>​		以上两种模式，<mark>main方法都是在客户端执行</mark>，需要<strong>获取 flink 运行时所需的依赖项，并生成 JobGraph，提交到集群的操作都会在实时平台所在的机器上执行</strong>，那么将会给服务器造成很大的压力。此外，提交任务的时候会<strong>把本地flink的所有jar包先上传到hdfs上相应的临时目录</strong>，带来<mark>大量的网络的开销</mark>，所以如果任务特别多的情况下，平台的吞吐量将会直线下降。</p>
<blockquote>
<p>​		Application 模式下，<mark>用户程序的 main 方法将在<code>集群</code>中运行</mark>，用户<strong>将程序逻辑和依赖打包进一个可执行的 jar 包里</strong>，集群的入口程序 (ApplicationClusterEntryPoint) 负责调用其中的 main 方法来生成 JobGraph。</p>
</blockquote>
<p><img src="1633436948989.png" alt="1633436948989" /></p>
<p>​		<strong>Application 模式为每个提交的应用程序创建一个集群，并在应用程序完成时终止</strong>。Application 模式在不同应用之间提供了资源隔离和负载平衡保证。在特定一个应用程序上，JobManager 执行 main() 可以节省所需的 CPU 周期，还可以节省本地下载依赖项所需的带宽。</p>
<p>​</p>

      
    </div>
    <footer class="article-footer">
      
      
      
      
      
      
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item" data-aos="zoom-in"><a class="article-tag-list-link" href="/en/tags/flink/" rel="tag">flink</a></li></ul>


    </footer>
  </div>
  
  <nav id="article-nav" data-aos="fade-up">
    
      
      <div class="article-nav-link-wrap article-nav-link-left">
        
          
          
            <img data-src="/covers/fll.jpg" data-sizes="auto" alt="推理判断" class="lazyload">
          
        
        <a href="/en/2023/07/13/%E6%8E%A8%E7%90%86%E5%88%A4%E6%96%AD/"></a>
        <div class="article-nav-caption">Prev</div>
        <h3 class="article-nav-title">
          
            推理判断
          
        </h3>
      </div>
    
    
    
    <div class="article-nav-link-wrap article-nav-link-right">
      
        
        
          <img data-src="/covers/fll.jpg" data-sizes="auto" alt="markdown学习" class="lazyload">
        
      
      <a href="/en/2022/11/28/Markdown%E5%AD%A6%E4%B9%A0/"></a>
      <div class="article-nav-caption">Next</div>
      <h3 class="article-nav-title">
        
          markdown学习
        
      </h3>
    </div>
    
  </nav>


</article>










</section>
        </div>
        <footer id="footer">
  <div style="width: 100%; overflow: hidden">
    <div class="footer-line"></div>
  </div>
  <div id="footer-info">
    
    <div>
      <span class="icon-copyright"></span>
      
      
      
        2021-2025
      
      <span class="footer-info-sep rotate"></span>
      小白
    </div>
    
      <div>
        Powered by&nbsp;<a href="https://hexo.io/" rel="noopener external nofollow noreferrer" target="_blank">Hexo</a>&nbsp;
        Theme.<a href="https://github.com/D-Sketon/hexo-theme-reimu" rel="noopener external nofollow noreferrer" target="_blank">Reimu</a>
      </div>
    
    
      <div>
        <span class="icon-brush"></span>
        482.3k
        &nbsp;|&nbsp;
        <span class="icon-coffee"></span>
        28:07
      </div>
    
    
    
    
    
      <div>
        <span class="icon-eye"></span>
        <span id="busuanzi_container_site_pv">Number of visits&nbsp;<span id="busuanzi_value_site_pv"></span></span>
        &nbsp;|&nbsp;
        <span class="icon-user"></span>
        <span id="busuanzi_container_site_uv">Number of visitors&nbsp;<span id="busuanzi_value_site_uv"></span></span>
      </div>
    
  </div>
</footer>

        
          <div class="sidebar-top">
            <div class="sidebar-top-taichi rotate"></div>
            <div class="arrow-up"></div>
          </div>
        
        <div id="mask" class="hide"></div>
      </div>
      <nav id="mobile-nav">
  <div class="sidebar-wrap">
    
      
        <div class="sidebar-toc-sidebar"><h3 class="toc-title">Contents</h3>
<div class="sidebar-toc-wrapper toc-div-class" >
  
    <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%89%8D%E8%A8%80%E9%83%A8%E5%88%86%E7%9F%A5%E8%AF%86%E5%9B%9E%E9%A1%BE%E5%8F%8A%E8%AF%BE%E7%A8%8B%E7%9B%AE%E6%A0%87"><span class="toc-number">1.</span> <span class="toc-text"> 前言部分：知识回顾及课程目标</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%89%8D%E8%A8%801-%E8%AF%BE%E7%A8%8B%E5%89%8D%E8%A8%80%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E5%BC%95%E6%93%8E"><span class="toc-number">1.1.</span> <span class="toc-text"> [前言1]-课程前言：大数据分析引擎</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%89%8D%E8%A8%802-apache-flink-%E8%AF%BE%E7%A8%8B%E5%AE%89%E6%8E%92"><span class="toc-number">1.2.</span> <span class="toc-text"> [前言2]-Apache Flink  课程安排</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%89%8D%E8%A8%803-%E7%AC%AC1%E7%AB%A0%E8%AF%BE%E7%A8%8B%E5%86%85%E5%AE%B9%E6%8F%90%E7%BA%B2"><span class="toc-number">1.3.</span> <span class="toc-text"> [前言3]-第1章：课程内容提纲</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%AC%AC%E4%B8%80%E9%83%A8%E5%88%86flink-%E6%A1%86%E6%9E%B6%E6%A6%82%E8%BF%B03%E4%B8%AA%E5%B0%8F%E8%8A%82"><span class="toc-number">2.</span> <span class="toc-text"> 第一部分：Flink 框架概述【3个小节】</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#01-%E7%90%86%E8%A7%A3-flink-%E6%A6%82%E8%BF%B0%E4%B9%8B%E5%AE%98%E6%96%B9%E5%AE%9A%E4%B9%89"><span class="toc-number">2.1.</span> <span class="toc-text"> 01-[理解]-Flink 概述之官方定义</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#02-%E6%8E%8C%E6%8F%A1-flink-%E6%A6%82%E8%BF%B0%E4%B9%8B%E6%B5%81%E5%BC%8F%E8%AE%A1%E7%AE%97%E6%80%9D%E6%83%B3"><span class="toc-number">2.2.</span> <span class="toc-text"> 02-[掌握]-Flink 概述之流式计算思想</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#03-%E4%BA%86%E8%A7%A3-flink-%E6%A6%82%E8%BF%B0%E4%B9%8B%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF"><span class="toc-number">2.3.</span> <span class="toc-text"> 03-[了解]-Flink 概述之应用场景</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%AC%AC%E4%BA%8C%E9%83%A8%E5%88%86flink-%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B29%E4%B8%AA%E5%B0%8F%E8%8A%82"><span class="toc-number">3.</span> <span class="toc-text"> 第二部分：Flink 安装部署【9个小节】</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#04-%E6%8E%8C%E6%8F%A1-%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2%E4%B9%8Bflink-cluster-%E6%9E%B6%E6%9E%84"><span class="toc-number">3.1.</span> <span class="toc-text"> 04-[掌握]-安装部署之Flink Cluster 架构</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#05-%E7%90%86%E8%A7%A3-%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2%E4%B9%8B%E6%9C%AC%E5%9C%B0%E9%9B%86%E7%BE%A4"><span class="toc-number">3.2.</span> <span class="toc-text"> 05-[理解]-安装部署之本地集群</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#06-%E7%90%86%E8%A7%A3-%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2%E4%B9%8Bstandalone-%E9%9B%86%E7%BE%A4"><span class="toc-number">3.3.</span> <span class="toc-text"> 06-[理解]-安装部署之Standalone 集群</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#07-%E4%BA%86%E8%A7%A3-%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2%E4%B9%8Bstandalone-ha"><span class="toc-number">3.4.</span> <span class="toc-text"> 07-[了解]-安装部署之Standalone HA</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#08-%E6%8E%8C%E6%8F%A1-flink-on-yarn%E4%B9%8B%E8%BF%90%E8%A1%8C%E6%B5%81%E7%A8%8B"><span class="toc-number">3.5.</span> <span class="toc-text"> 08-[掌握]-Flink on YARN之运行流程</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#09-%E7%90%86%E8%A7%A3-flink-on-yarn%E4%B9%8B%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2"><span class="toc-number">3.6.</span> <span class="toc-text"> 09-[理解]-Flink on YARN之安装部署</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#10-%E6%8E%8C%E6%8F%A1-flink-on-yarn%E4%B9%8Bsession-%E6%A8%A1%E5%BC%8F%E8%BF%90%E8%A1%8C"><span class="toc-number">3.7.</span> <span class="toc-text"> 10-[掌握]-Flink on YARN之Session 模式运行</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#11-%E6%8E%8C%E6%8F%A1-flink-on-yarn%E4%B9%8Bper-job-%E6%A8%A1%E5%BC%8F%E8%BF%90%E8%A1%8C"><span class="toc-number">3.8.</span> <span class="toc-text"> 11-[掌握]-Flink on YARN之Per-Job 模式运行</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#12-%E6%8E%8C%E6%8F%A1-flink-on-yarn%E4%B9%8Bapplication-%E6%A8%A1%E5%BC%8F%E8%BF%90%E8%A1%8C"><span class="toc-number">3.9.</span> <span class="toc-text"> 12-[掌握]-Flink on YARN之Application 模式运行</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%AC%AC%E4%B8%89%E9%83%A8%E5%88%86flink-%E5%85%A5%E9%97%A8%E6%A1%88%E4%BE%8B4%E4%B8%AA%E5%B0%8F%E8%8A%82"><span class="toc-number">4.</span> <span class="toc-text"> 第三部分：Flink 入门案例【4个小节】</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#13-%E6%8E%8C%E6%8F%A1-flink-%E5%85%A5%E9%97%A8%E6%A1%88%E4%BE%8B%E4%B9%8B%E7%BC%96%E7%A8%8B%E6%A8%A1%E5%9E%8B"><span class="toc-number">4.1.</span> <span class="toc-text"> 13-[掌握]-Flink 入门案例之编程模型</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#14-%E6%8E%8C%E6%8F%A1-flink-%E5%85%A5%E9%97%A8%E6%A1%88%E4%BE%8B%E4%B9%8Bwordcount%E6%89%B9%E5%A4%84%E7%90%86"><span class="toc-number">4.2.</span> <span class="toc-text"> 14-[掌握]-Flink 入门案例之WordCount【批处理】</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#15-%E6%8E%8C%E6%8F%A1-flink-%E5%85%A5%E9%97%A8%E6%A1%88%E4%BE%8B%E4%B9%8Bwordcount%E6%B5%81%E8%AE%A1%E7%AE%97"><span class="toc-number">4.3.</span> <span class="toc-text"> 15-[掌握]-Flink 入门案例之WordCount【流计算】</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#16-%E6%8E%8C%E6%8F%A1-flink-%E5%85%A5%E9%97%A8%E6%A1%88%E4%BE%8B%E4%B9%8B%E6%89%93%E5%8C%85%E9%83%A8%E7%BD%B2%E8%BF%90%E8%A1%8C"><span class="toc-number">4.4.</span> <span class="toc-text"> 16-[掌握]-Flink 入门案例之打包部署运行</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%99%84%E5%BD%95%E9%83%A8%E5%88%86%E6%B3%A8%E6%84%8F%E4%BA%8B%E9%A1%B9%E5%8F%8A%E6%89%A9%E5%B1%95%E5%86%85%E5%AE%B9"><span class="toc-number">5.</span> <span class="toc-text"> 附录部分：注意事项及扩展内容</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%99%84%E5%BD%951-%E6%B5%81%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E%E7%9A%84%E6%BC%94%E8%BF%9B"><span class="toc-number">5.1.</span> <span class="toc-text"> [附录1]-流计算引擎的演进</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%99%84%E5%BD%952-flink-%E6%A1%86%E6%9E%B6%E6%8A%80%E6%9C%AF%E6%A0%88"><span class="toc-number">5.2.</span> <span class="toc-text"> [附录2]-Flink 框架技术栈</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%99%84%E5%BD%953-flink-%E6%89%A9%E5%B1%95%E6%80%A7%E9%98%85%E8%AF%BB"><span class="toc-number">5.3.</span> <span class="toc-text"> [附录3]-Flink 扩展性阅读</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%99%84%E5%BD%954-flink-standalone-%E9%9B%86%E7%BE%A4%E5%9B%9E%E9%A1%BE"><span class="toc-number">5.4.</span> <span class="toc-text"> [附录4]-Flink Standalone 集群回顾</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%99%84%E5%BD%955-hadoop-yarn-%E5%9B%9E%E9%A1%BE%E5%A4%8D%E4%B9%A0"><span class="toc-number">5.5.</span> <span class="toc-text"> [附录5]-Hadoop YARN 回顾复习</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%99%84%E5%BD%956-flink-on-yarn-%E4%B8%89%E7%A7%8D%E9%83%A8%E7%BD%B2%E6%A8%A1%E5%BC%8F"><span class="toc-number">5.6.</span> <span class="toc-text"> [附录6]-Flink on YARN 三种部署模式</span></a></li></ol></li></ol>
  
</div>
</div>
        <div class="sidebar-common-sidebar hidden"><div class="sidebar-author">
  <img data-src="/avatar/avatar.webp" data-sizes="auto" alt="小白" class="lazyload">
  <div class="sidebar-author-name">小白</div>
  <div class="sidebar-description"></div>
</div>
<div class="sidebar-state">
  <div class="sidebar-state-article">
    <div>Post</div>
    <div class="sidebar-state-number">21</div>
  </div>
  <div class="sidebar-state-category">
    <div>Category</div>
    <div class="sidebar-state-number">6</div>
  </div>
  <div class="sidebar-state-tag">
    <div>Tag</div>
    <div class="sidebar-state-number">13</div>
  </div>
</div>
<div class="sidebar-social">
  
    <div class="icon-steam sidebar-social-icon">
      <a href=https://steamcommunity.com/id/yourname itemprop="url" target="_blank" aria-label="steam" rel="noopener external nofollow noreferrer"></a>
    </div>
  
</div>
<div class="sidebar-menu">
  
    
      <div class="sidebar-menu-link-wrap">
        <a class="sidebar-menu-link-dummy" href="/en/" aria-label="Home"></a>
        <div class="sidebar-menu-icon icon rotate">
          
            &#xe62b;
          
        </div>
        <div class="sidebar-menu-link">Home</div>
      </div>
    
      <div class="sidebar-menu-link-wrap">
        <a class="sidebar-menu-link-dummy" href="/en/archives" aria-label="Archives"></a>
        <div class="sidebar-menu-icon icon rotate">
          
            &#xe62b;
          
        </div>
        <div class="sidebar-menu-link">Archives</div>
      </div>
    
      <div class="sidebar-menu-link-wrap">
        <a class="sidebar-menu-link-dummy" href="/en/about" aria-label="About"></a>
        <div class="sidebar-menu-icon icon rotate">
          
            &#xe62b;
          
        </div>
        <div class="sidebar-menu-link">About</div>
      </div>
    
      <div class="sidebar-menu-link-wrap">
        <a class="sidebar-menu-link-dummy" href="/en/friend" aria-label="Friend"></a>
        <div class="sidebar-menu-icon icon rotate">
          
            &#xe62b;
          
        </div>
        <div class="sidebar-menu-link">Friend</div>
      </div>
    
  
</div>
</div>
      
    
  </div>
  
    
      <div class="sidebar-btn-wrapper">
        <div class="sidebar-toc-btn current"></div>
        <div class="sidebar-common-btn"></div>
      </div>
    
  
</nav>

    </div>
    
      <div class="site-search">
        <div class="reimu-popup popup">
          <div class="reimu-search">
            <div class="reimu-search-input-icon"></div>
            <div class="reimu-search-input" id="reimu-search-input"></div>
            <div class="popup-btn-close"></div>
          </div>
          <div class="reimu-results">
            <div id="reimu-stats"></div>
            <div id="reimu-hits"></div>
            <div id="reimu-pagination" class="reimu-pagination"></div>
          </div>
          <img class="reimu-bg" src="/images/reimu.png"/>
        </div>
      </div>
    
    
    
    
<script src="https://npm.webcache.cn/lazysizes@5.3.2/lazysizes.min.js" integrity="sha384-3gT&#x2F;vsepWkfz&#x2F;ff7PpWNUeMzeWoH3cDhm&#x2F;A8jM7ouoAK0&#x2F;fP&#x2F;9bcHHR5kHq2nf+e" crossorigin="anonymous"></script>


<script src="https://npm.webcache.cn/clipboard@2.0.11/dist/clipboard.min.js" integrity="sha384-J08i8An&#x2F;QeARD9ExYpvphB8BsyOj3Gh2TSh1aLINKO3L0cMSH2dN3E22zFoXEi0Q" crossorigin="anonymous"></script>





<script src="/js/script.js"></script>



  
<script src="/js/aos.js"></script>

  <script>
    var aosInit = () => {
      AOS.init({
        duration: 1000,
        easing: "ease",
        once: true,
        offset: 50,
      });
    };
    if (document.readyState === 'loading') {
      document.addEventListener('DOMContentLoaded', aosInit);
    } else {
      aosInit();
    }
  </script>



<script src="/js/pjax_script.js" data-pjax></script>



  
<script src="/js/generator_search.js" defer></script>






  
<script src="https://npm.webcache.cn/mouse-firework@0.1.1/dist/index.umd.js" integrity="sha384-8LyaidD9GPxQQgLJO&#x2F;WRw&#x2F;O2h3BoNq&#x2F;ApI&#x2F;ecpvM6RsrCz2qP2ppBXUKihP4V&#x2F;2d" crossorigin="anonymous"></script>

  <script>
    window.firework && window.firework(JSON.parse('{"excludeElements":["a","button"],"particles":[{"shape":"circle","move":["emit"],"easing":"easeOutExpo","colors":["var(--red-1)","var(--red-2)","var(--red-3)","var(--red-4)"],"number":20,"duration":[1200,1800],"shapeOptions":{"radius":[16,32],"alpha":[0.3,0.5]}},{"shape":"circle","move":["diffuse"],"easing":"easeOutExpo","colors":["var(--red-0)"],"number":1,"duration":[1200,1800],"shapeOptions":{"radius":20,"alpha":[0.2,0.5],"lineWidth":6}}]}'))
  </script>



  
<script src="https://npm.webcache.cn/theme-shokax-pjax@0.0.3/dist/index.umd.js" integrity="sha384-xneY1WY8hOfUzswrE4CrYq35N4BdVcxqxwHPr9zawE&#x2F;jMSCxD+jAPU55x&#x2F;jj3wlf" crossorigin="anonymous"></script>

  <script>
    function loadScripts(scripts, index) {
      if (index < scripts.length) {
        const script = scripts[index];
        const src = script.getAttribute('src');

        const loadScript = (scriptContent) => {
          return new Promise((resolve, reject) => {
            const scriptElement = document.createElement('script');
            if (script.type) {
              scriptElement.type = script.type;
            }
            if (script.src) {
              scriptElement.src = script.src;
              if (script.integrity) {
                scriptElement.integrity = script.integrity;
              }
              if (script.crossOrigin) {
                scriptElement.crossOrigin = script.crossOrigin;
              }
              scriptElement.onload = resolve;
              scriptElement.onerror = reject;
            }
            if (scriptContent) {
              scriptElement.text = scriptContent;
            }
            document.head.appendChild(scriptElement);
            if (!script.src) {
              resolve();
            }
          })
          
        }

        ;(src ? loadScript() : loadScript(script.text))
          .then(() => loadScripts(scripts, index + 1))
          .catch(error => {
            console.error(`Failed to load script: ${src || 'inline script'}`, error);
            loadScripts(scripts, index + 1);
          });
      }
    }
    if (window.Pjax) {
      Pjax.prototype.getElements = function() {
        const i18nLanguages = window.REIMU_CONFIG.i18n_languages;
        const baseUrl = window.REIMU_CONFIG.base;
        let basePathname = new URL(baseUrl).pathname;
        if (!basePathname.endsWith('/')) {
          basePathname += '/';  
        }
        const currentUrl = window.location.href;
        const currentPathname = new URL(currentUrl).pathname.replace(basePathname, '');
        const aLinks = document.querySelectorAll('a[href]');
        const pjaxLinks = [];
        for(let i = 0; i < aLinks.length; i++) {
          const aLink = aLinks[i];
          const aLinkHref = aLink.getAttribute('href');
          const isExternal = aLink.getAttribute('target') === '_blank' || aLink.getAttribute('rel')?.includes('noopener');
          if (isExternal || aLinkHref.startsWith('mailto:') || aLinkHref.startsWith('tel:') || aLinkHref.startsWith('javascript:') || aLinkHref.startsWith("data:") || aLinkHref.startsWith("vbscript:")) {
            continue;
          }
          if (!i18nLanguages) {
            // 多语言功能未打开
            pjaxLinks.push(aLink);
            continue;
          }

          const absoluteUrl = new URL(aLinkHref, currentUrl).href;
          const absolutePathname = new URL(absoluteUrl).pathname.replace(basePathname, '');

          if (!absolutePathname || !currentPathname) {
            pjaxLinks.push(aLink);
            continue;
          }

          const currentLangIndex = i18nLanguages.findIndex(lang => currentPathname.startsWith(lang));
          if (currentLangIndex > -1) {
            // 当前属于多语言站点
            const absoluteLangIndex = i18nLanguages.findIndex(lang => absolutePathname.startsWith(lang));
            if (absoluteLangIndex === currentLangIndex) {
              // 同一语言站点，可以使用 pjax
              pjaxLinks.push(aLink);
            }
          } else {
            // 当前属于默认语言站点
            const absoluteLangIndex = i18nLanguages.findIndex(lang => absolutePathname.startsWith(lang));
            if (absoluteLangIndex === -1) {
              // 同一语言站点，可以使用 pjax
              pjaxLinks.push(aLink);
            }
          }
        }
        return pjaxLinks;
      }
    }
    window.Pjax && new window.Pjax({
      selectors: [
        "#header>img",
        "#header>picture",
        "head title",
        "#header-title",
        "#subtitle-wrap",
        "#main",
        "#content",
        ".sidebar-widget",
        ".sidebar-wrapper",
        ".sidebar-wrapper-container",
        '#mobile-nav',
        '#lazy-script',
        '#i18n-nav'
      ],
      switches: {
        ".sidebar-wrapper-container": function(oldEl, newEl) {
          oldEl.className = newEl.className;
          this.onSwitch();
        },
        "#content": function(oldEl, newEl) {
          // for sidebar change
          oldEl.className = newEl.className;
          this.onSwitch();
        },
        "#header-title": Pjax.switches.outerHTML,
        "#subtitle-wrap": Pjax.switches.outerHTML,
        "#main": function(oldEl, newEl) {
          const scripts = [...newEl.querySelectorAll('script')];
          loadScripts(scripts, 0);
          oldEl.outerHTML = newEl.outerHTML
          this.onSwitch()
        },
        "#mobile-nav": Pjax.switches.outerHTML,
        '#lazy-script': function(oldEl, newEl) {
          const scripts = [...newEl.querySelectorAll('script')];
          loadScripts(scripts, 0);
          oldEl.innerHTML = newEl.innerHTML
          this.onSwitch()
        },
      },
      cacheBust: false
    })
  </script>
  
<script src="/js/pjax.js"></script>








  
<script src="https://npm.webcache.cn/quicklink@2.3.0/dist/quicklink.umd.js" integrity="sha384-aD7FsuQkS1ohgFKY41fJfeA+Wd&#x2F;QRNnrOd9Bs58K3FzKdJJv8yPnYU8Tnp5z1agS" crossorigin="anonymous"></script>

  <script data-pjax>
    window.quicklink?.listen({
      timeout: 3000,
      priority: true,
      ignores: []
    });
  </script>


<div id="lazy-script">
  <div>
    
      
      
      <script data-pjax>
        window.REIMU_POST = {
          author: "小白",
          title: "Flink基础入门",
          url: "https://caoxiaobai1.github.io/2022/11/28/Flink%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8/",
          excerpt: "",
          description: "",
          stripContent: " ​   Apache Flink是一个框架和分布式处理引擎，用于对无界和有界数据流进行有状态计算。Flink设计为在所有常见的集群环境中运行，以内存速度和任何规模执行计算。    ​  本次课程基于2021年05月28日发布的Flink 1.13.1版本讲解，此版本重要功能：让流处理应用的使用和普通应用一样简单和自然。https://developer.aliyun.com/article/780123    前言部分：知识回顾及课程目标  [前言1]-课程前言：大数据分析引擎   整个大数据",
          date: "Mon Nov 28 2022 20:30:20 GMT+0800",
          updated: "Mon Sep 08 2025 13:59:12 GMT+0800",
          cover: "/images/banner.webp",
        };
      </script>
       
    
    
      
        
<script src="/js/insert_highlight.js" data-pjax></script>

        
      
    
    
      <script type="module" data-pjax>
        const PhotoSwipeLightbox = (await safeImport("https://npm.webcache.cn/photoswipe@5.4.4/dist/photoswipe-lightbox.esm.min.js", "sha384-DiL6M/gG+wmTxmCRZyD1zee6lIhawn5TGvED0FOh7fXcN9B0aZ9dexSF/N6lrZi/")).default;
        
        const pswp = () => {
          if (_$$('.article-entry a.article-gallery-item').length > 0) {
            new PhotoSwipeLightbox({
              gallery: '.article-entry',
              children: 'a.article-gallery-item',
              pswpModule: () => safeImport("https://npm.webcache.cn/photoswipe@5.4.4/dist/photoswipe.esm.min.js", "sha384-WkkO3GCmgkC3VQWpaV8DqhKJqpzpF9JoByxDmnV8+oTJ7m3DfYEWX1fu1scuS4+s")
            }).init();
          }
          if(_$$('.article-gallery a.article-gallery-item').length > 0) {
            new PhotoSwipeLightbox({
              gallery: '.article-gallery',
              children: 'a.article-gallery-item',
              pswpModule: () => safeImport("https://npm.webcache.cn/photoswipe@5.4.4/dist/photoswipe.esm.min.js", "sha384-WkkO3GCmgkC3VQWpaV8DqhKJqpzpF9JoByxDmnV8+oTJ7m3DfYEWX1fu1scuS4+s")
            }).init();
          }
          window.lightboxStatus = 'done';
          window.removeEventListener('lightbox:ready', pswp);
        }
        if(window.lightboxStatus === 'ready') {
          pswp()
        } else {
          window.addEventListener('lightbox:ready', pswp);
        }
      </script>
      
        








      
    
  </div>
</div>


  <script>
    console.log(String.raw`%c 
 ______     ______     __     __    __     __  __    
/\  == \   /\  ___\   /\ \   /\ "-./  \   /\ \/\ \   
\ \  __<   \ \  __\   \ \ \  \ \ \-./\ \  \ \ \_\ \  
 \ \_\ \_\  \ \_____\  \ \_\  \ \_\ \ \_\  \ \_____\ 
  \/_/ /_/   \/_____/   \/_/   \/_/  \/_/   \/_____/ 
                                                  
`,'color: #ff5252;')
    console.log('%c Theme.Reimu v' + '1.9.1' + ' %c https://github.com/D-Sketon/hexo-theme-reimu ', 'color: white; background: #ff5252; padding:5px 0;', 'padding:4px;border:1px solid #ff5252;')
  </script>
  



  
<script src="https://npm.webcache.cn/busuanzi@2.3.0/bsz.pure.mini.js" integrity="sha384-0M75wtSkhjIInv4coYlaJU83+OypaRCIq2SukQVQX04eGTCBXJDuWAbJet56id+S" crossorigin="anonymous" async></script>




<script>
  if ('serviceWorker' in navigator) {
    navigator.serviceWorker.getRegistrations().then((registrations) => {
      for (let registration of registrations) {
        registration.unregister();
      }
    });
  }
</script>



  



  
<script src="https://npm.webcache.cn/aplayer@1.10.1/dist/APlayer.min.js" integrity="sha384-gdGYZwHnfJM54evoZhpO0s6ZF5BQiybkiyW7VXr+h5UfruuRL&#x2F;aORyw+5+HZoU6e" crossorigin="anonymous"></script>

  
    <script>
      var isMobile = window.matchMedia('(max-width: 959px)').matches;
      if (isMobile) {
      const aplayer = _$('#aplayer');
        if (aplayer) {
          const aside = aplayer.parentNode;
          if (aside?.tagName === 'ASIDE') {
            aplayer.removeAttribute('data-aos');
            aside.removeChild(aplayer);
            document.body.appendChild(aplayer);
          }
        }
      }
      const ap = new APlayer({
        theme: "var(--color-link)",
        container: document.getElementById('aplayer'),
        audio: [] || [],
        fixed: isMobile ? true : (false || false),
        autoplay: false || false,
        loop: 'all' || 'all',
        order: 'list' || 'list',
        preload: 'auto' || 'auto',
        volume: 0.7 || 0.7,
        mutex: true || true,
        listFolded: false || false,
        lrcType: 0 || 0,
      });
    </script>
  





    
  </body>
  </html>

